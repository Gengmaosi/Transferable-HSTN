{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-store",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import copy\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from typing import Any,Dict,List\n",
    "\n",
    "padding_keys = ['HISTORY','FUTURE','NORM_CENTER','LANE_VECTORS','NEW_LANES','CLASS_LIST']\n",
    "stacking_keys = ['VALID_LEN']\n",
    "listing_keys = ['TARGET_MASK','LANE_ID','HEADINGS','RAW_HISTORY','RAW_FUTURE']\n",
    "\n",
    "def collate_single_cpu(batch):\n",
    "\n",
    "    keys = batch[0].keys()\n",
    "\n",
    "    out = {k: [] for k in keys}\n",
    "\n",
    "    for data in batch:\n",
    "        for k, v in data.items():\n",
    "            out[k].append(v)\n",
    "    \n",
    "    # stacking\n",
    "    for k in stacking_keys:\n",
    "        out[k] = torch.stack(out[k], dim=0)\n",
    "    \n",
    "    # padding\n",
    "    for k in padding_keys:\n",
    "        out[k] = pad_sequence(out[k], batch_first=True)\n",
    "    \n",
    "    return out\n",
    "\n",
    "class inDDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        super(inDDataset, self).__init__()\n",
    "\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        data_dict = self.get_data(idx)\n",
    "\n",
    "        return data_dict\n",
    "\n",
    "    def get_data(self, idx):\n",
    "        \n",
    "        out_dict = {}\n",
    "        \n",
    "        datadict = self.data[idx]\n",
    "        out_dict.update(datadict)\n",
    "\n",
    "        for k, v in out_dict.items():\n",
    "            if isinstance(v, np.ndarray):\n",
    "                v = torch.from_numpy(v).to(device)\n",
    "            \n",
    "                if v.dtype == torch.double:\n",
    "                    v = v.type(torch.float32).to(device)\n",
    "            \n",
    "                out_dict[k] = v\n",
    "\n",
    "        return out_dict\n",
    "\n",
    "def pad_track(\n",
    "        track_df: pd.DataFrame,\n",
    "        seq_timestamps: np.ndarray,\n",
    "        base: int,\n",
    "        track_len: int,\n",
    "        raw_data_format: Dict[str, int],\n",
    ") -> np.ndarray:\n",
    "    \n",
    "    track_vals = track_df.values\n",
    "    track_timestamps = track_df['frame'].values\n",
    "    seq_timestamps = seq_timestamps[base:base+track_len]\n",
    "\n",
    "    start_idx = np.where(seq_timestamps == track_timestamps[0])[0][0]\n",
    "    end_idx = np.where(seq_timestamps == track_timestamps[-1])[0][0]\n",
    "\n",
    "    padded_track_array = np.pad(track_vals,\n",
    "                                ((start_idx, track_len - end_idx - 1),\n",
    "                                    (0, 0)), \"edge\")\n",
    "\n",
    "    mask = np.ones((end_idx+1-start_idx))\n",
    "    mask = np.pad(mask, (start_idx, track_len - end_idx - 1), 'constant')\n",
    "    if padded_track_array.shape[0] < track_len:\n",
    "        return None, None, False\n",
    "\n",
    "    for i in range(padded_track_array.shape[0]):\n",
    "        padded_track_array[i, 0] = seq_timestamps[i]\n",
    "    assert mask.shape[0] == padded_track_array.shape[0]\n",
    "    return padded_track_array, mask, True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-puppy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "processed_data_path = r'intersectionA_data_with_map.pkl'\n",
    "with open(processed_data_path, 'rb') as f:\n",
    "    data_location1 = pickle.load(f)\n",
    "\n",
    "processed_data_path = r'intersectionB_data_with_map.pkl'\n",
    "with open(processed_data_path, 'rb') as f:\n",
    "    data_location2 = pickle.load(f)\n",
    "\n",
    "processed_data_path = r'intersectionC_data_with_map.pkl'\n",
    "with open(processed_data_path, 'rb') as f:\n",
    "    data_location3 = pickle.load(f)\n",
    "    \n",
    "processed_data_path = r'intersectionD_data_with_map.pkl'\n",
    "with open(processed_data_path, 'rb') as f:\n",
    "    data_location4 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-miracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#intersection A is the target domainï¼Œother three intersections are source domains\n",
    "\n",
    "def series_impute(small_train,small_val,small_test,size_train,size_val,size_test):\n",
    "    if len(small_train) == size_train and len(small_val) == size_val and len(small_test) == size_test:\n",
    "        return small_train,small_val,small_test\n",
    "    train_tmp = small_train\n",
    "    val_tmp = small_val\n",
    "    test_tmp = small_test\n",
    "    for i in range (math.ceil(size_train/len(small_train))):\n",
    "        #print(math.ceil(size_train/len(small_train)))\n",
    "        train_tmp = np.concatenate((train_tmp,small_train), axis = 0)\n",
    "    if math.ceil(size_train/len(small_train))==0:\n",
    "        train_tmp = small_train\n",
    "    train_tmp = train_tmp[:size_train]\n",
    "    \n",
    "    for i in range (math.ceil(size_val/len(small_val))):\n",
    "        val_tmp = np.concatenate((val_tmp,small_val), axis = 0)\n",
    "    if math.ceil(size_val/len(small_val))==0:\n",
    "        val_tmp = small_val\n",
    "    val_tmp = val_tmp[:size_val]\n",
    "    \n",
    "    for i in range (math.ceil(size_test/len(small_test))):\n",
    "        test_tmp = np.concatenate((test_tmp,small_test), axis = 0)\n",
    "    if math.ceil(size_test/len(small_test))==0:\n",
    "        test_tmp = small_test\n",
    "    test_tmp = test_tmp[:size_test]\n",
    "\n",
    "    return train_tmp, val_tmp, test_tmp\n",
    "\n",
    "def random_split_data(total_data,mr):\n",
    "    shuffled_indices = np.random.permutation(len(total_data))\n",
    "    train_indices = shuffled_indices[:int(0.8*mr*len(total_data))]\n",
    "    val_indices = shuffled_indices[int(len(total_data)*0.8):int(len(total_data)*0.9)]\n",
    "    test_indices = shuffled_indices[int(len(total_data)*0.9):]\n",
    "\n",
    "    train_data = []\n",
    "    val_data = []\n",
    "    test_data = []\n",
    "    for ind in train_indices:\n",
    "        train_data.append(total_data[ind])\n",
    "    for ind in val_indices:\n",
    "        val_data.append(total_data[ind])\n",
    "    for ind in test_indices:\n",
    "        test_data.append(total_data[ind])\n",
    "        \n",
    "    return train_data,val_data,test_data\n",
    "\n",
    "train_data1,val_data1,test_data1 = random_split_data(data_location1,0.0001)\n",
    "train_data2,val_data2,test_data2 = random_split_data(data_location2,1)\n",
    "train_data3,val_data3,test_data3 = random_split_data(data_location3,1)\n",
    "train_data4,val_data4,test_data4 = random_split_data(data_location4,1)\n",
    "\n",
    "print(len(train_data1),len(val_data1),len(test_data1))\n",
    "print(len(train_data2),len(val_data2),len(test_data2))\n",
    "print(len(train_data4),len(val_data4),len(test_data4))\n",
    "\n",
    "import math\n",
    "\n",
    "size_train = int(max(len(train_data1),len(train_data2),len(train_data3),len(train_data4))*(3/3))\n",
    "size_val = int(max(len(val_data1),len(val_data2),len(val_data3),len(val_data4))*(3/3))\n",
    "size_test = int(max(len(test_data1),len(test_data2),len(test_data3),len(test_data4))*(3/3))\n",
    "\n",
    "#train_data1,val_data1,test_data1 = series_impute(train_data1,val_data1,test_data1,size_train,size_val,size_test)\n",
    "train_data2,val_data2,test_data2 = series_impute(train_data2,val_data2,test_data2,size_train,size_val,size_test)\n",
    "train_data3,val_data3,test_data3 = series_impute(train_data3,val_data3,test_data3,size_train,size_val,size_test)\n",
    "train_data4,val_data4,test_data4 = series_impute(train_data4,val_data4,test_data4,size_train,size_val,size_test)\n",
    "\n",
    "print(len(train_data1),len(val_data1),len(test_data1))\n",
    "print(len(train_data2),len(val_data2),len(test_data2))\n",
    "print(len(train_data4),len(val_data4),len(test_data4))\n",
    "\n",
    "train_s1_Dataset = inDDataset(train_data4)\n",
    "train_s1_dataloader = DataLoader(train_s1_Dataset,shuffle=True,batch_size=32,num_workers=0,collate_fn=collate_single_cpu,drop_last=True)\n",
    "val_s1_Dataset = inDDataset(val_data4)\n",
    "val_s1_dataloader = DataLoader(val_s1_Dataset,shuffle=False,batch_size=32,num_workers=0,collate_fn=collate_single_cpu,drop_last=True)\n",
    "test_s1_Dataset = inDDataset(test_data4)\n",
    "test_s1_dataloader = DataLoader(test_s1_Dataset,shuffle=False,batch_size=32,num_workers=0,collate_fn=collate_single_cpu,drop_last=True)\n",
    "\n",
    "train_s2_Dataset = inDDataset(train_data2)\n",
    "train_s2_dataloader = DataLoader(train_s2_Dataset,shuffle=True,batch_size=32,num_workers=0,collate_fn=collate_single_cpu,drop_last=True)\n",
    "val_s2_Dataset = inDDataset(val_data2)\n",
    "val_s2_dataloader = DataLoader(val_s2_Dataset,shuffle=False,batch_size=32,num_workers=0,collate_fn=collate_single_cpu,drop_last=True)\n",
    "test_s2_Dataset = inDDataset(test_data2)\n",
    "test_s2_dataloader = DataLoader(test_s2_Dataset,shuffle=False,batch_size=32,num_workers=0,collate_fn=collate_single_cpu,drop_last=True)\n",
    "\n",
    "train_s3_Dataset = inDDataset(train_data3)\n",
    "train_s3_dataloader = DataLoader(train_s3_Dataset,shuffle=True,batch_size=32,num_workers=0,collate_fn=collate_single_cpu,drop_last=True)\n",
    "val_s3_Dataset = inDDataset(val_data3)\n",
    "val_s3_dataloader = DataLoader(val_s3_Dataset,shuffle=False,batch_size=32,num_workers=0,collate_fn=collate_single_cpu,drop_last=True)\n",
    "test_s3_Dataset = inDDataset(test_data3)\n",
    "test_s3_dataloader = DataLoader(test_s3_Dataset,shuffle=False,batch_size=32,num_workers=0,collate_fn=collate_single_cpu,drop_last=True)\n",
    "\n",
    "train_t_Dataset = inDDataset(train_data1)\n",
    "train_t_dataloader = DataLoader(train_t_Dataset,shuffle=True,batch_size=32,num_workers=0,collate_fn=collate_single_cpu,drop_last=True)\n",
    "val_t_Dataset = inDDataset(val_data1)\n",
    "val_t_dataloader = DataLoader(val_t_Dataset,shuffle=False,batch_size=32,num_workers=0,collate_fn=collate_single_cpu,drop_last=True)\n",
    "test_t_Dataset = inDDataset(test_data1)\n",
    "test_t_dataloader = DataLoader(test_t_Dataset,shuffle=False,batch_size=16,num_workers=0,collate_fn=collate_single_cpu,drop_last=True)\n",
    "\n",
    "dataloaders = {}\n",
    "dataloaders['train_s1'] = train_s1_dataloader\n",
    "dataloaders['train_s2'] = train_s2_dataloader\n",
    "dataloaders['train_s3'] = train_s3_dataloader\n",
    "dataloaders['val_s1'] = val_s1_dataloader\n",
    "dataloaders['val_s2'] = val_s2_dataloader\n",
    "dataloaders['val_s3'] = val_s3_dataloader\n",
    "dataloaders['test_s1'] = test_s1_dataloader\n",
    "dataloaders['test_s2'] = test_s2_dataloader\n",
    "dataloaders['test_s3'] = test_s3_dataloader\n",
    "\n",
    "dataloaders['train_t'] = train_t_dataloader\n",
    "dataloaders['val_t'] = val_t_dataloader\n",
    "dataloaders['test_t'] = test_t_dataloader\n",
    "\n",
    "dataset_sizes = {}\n",
    "dataset_sizes['train_s'] = len(train_data1)\n",
    "dataset_sizes['val_s'] = len(val_data1)\n",
    "dataset_sizes['test_s'] = len(test_data1)\n",
    "dataset_sizes['train_t'] = len(train_data2)\n",
    "dataset_sizes['val_t'] = len(val_data2)\n",
    "dataset_sizes['test_t'] = len(test_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-volleyball",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1,val_data1,test_data1 = random_split_data(data_location1,0.0001)\n",
    "\n",
    "train_t_Dataset = inDDataset(train_data1)\n",
    "train_t_dataloader = DataLoader(train_t_Dataset,shuffle=True,batch_size=32,num_workers=0,collate_fn=collate_single_cpu,drop_last=True)\n",
    "val_t_Dataset = inDDataset(val_data1)\n",
    "val_t_dataloader = DataLoader(val_t_Dataset,shuffle=False,batch_size=32,num_workers=0,collate_fn=collate_single_cpu,drop_last=True)\n",
    "test_t_Dataset = inDDataset(test_data1)\n",
    "test_t_dataloader = DataLoader(test_t_Dataset,shuffle=False,batch_size=16,num_workers=0,collate_fn=collate_single_cpu,drop_last=True)\n",
    "\n",
    "dataloaders = {}\n",
    "dataloaders['train_t'] = train_t_dataloader\n",
    "dataloaders['val_t'] = val_t_dataloader\n",
    "dataloaders['test_t'] = test_t_dataloader\n",
    "\n",
    "dataset_sizes = {}\n",
    "dataset_sizes['train_t'] = len(train_data1)\n",
    "dataset_sizes['val_t'] = len(val_data1)\n",
    "dataset_sizes['test_t'] = len(test_data1)\n",
    "print(dataset_sizes['test_t'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-organizer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math, copy, time\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "from multi_attention_forward import multi_head_attention_forward\n",
    "\n",
    "class LaneNet(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_unit, num_subgraph_layers):\n",
    "        super(LaneNet, self).__init__()\n",
    "        self.num_subgraph_layers = num_subgraph_layers\n",
    "        self.layer_seq = nn.Sequential()\n",
    "        for i in range(num_subgraph_layers):\n",
    "            self.layer_seq.add_module(\n",
    "                f'lmlp_{i}', MLP(in_channels, hidden_unit))\n",
    "            in_channels = hidden_unit*2\n",
    "\n",
    "    def forward(self, lane):\n",
    "        \n",
    "        x = lane\n",
    "        for name, layer in self.layer_seq.named_modules():\n",
    "            if isinstance(layer, MLP):\n",
    "                x = layer(x)\n",
    "                x_max = torch.max(x, -2)[0]\n",
    "                x_max = x_max.unsqueeze(2).repeat(1, 1, x.shape[2], 1)\n",
    "                x = torch.cat([x, x_max], dim=-1)\n",
    "        x_max = torch.max(x, -2)[0]\n",
    "        return x_max\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_unit, verbose=False):\n",
    "        super(MLP, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(in_channels, hidden_unit),\n",
    "            nn.LayerNorm(hidden_unit),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mlp(x)\n",
    "        return x\n",
    "\n",
    "def preprocess_lane(lane_subgraph,lane,B, lane_valid_len, max_lane_num):\n",
    "    \n",
    "    lane_v = torch.cat(\n",
    "        [lane[:, :, :-1, :2],\n",
    "            lane[:, :, 1:, :2]], dim=-1).to(device)\n",
    "    \n",
    "    lane_mask = torch.zeros(\n",
    "        (B, 1, int(max_lane_num))).to(device)\n",
    "    for i in range(lane_valid_len.shape[0]):\n",
    "        lane_mask[i, 0, :lane_valid_len[i]] = 1\n",
    "    \n",
    "    lane_feature = lane_subgraph(lane_v)\n",
    "\n",
    "    return lane_feature, lane_mask\n",
    "\n",
    "def preprocess_traj(traj, B, traj_valid_len, max_agent_num):\n",
    "    \n",
    "    social_valid_len = traj_valid_len\n",
    "    social_mask = torch.zeros(\n",
    "        (B, 1, int(max_agent_num))).to(device)\n",
    "    for i in range(B):\n",
    "        social_mask[i, 0, :social_valid_len[i]] = 1\n",
    "\n",
    "    return social_mask\n",
    "\n",
    "\n",
    "def _get_activation_fn(activation):\n",
    "    if activation == \"relu\":\n",
    "        return F.relu\n",
    "    elif activation == \"gelu\":\n",
    "        return F.gelu\n",
    "    else:\n",
    "        raise RuntimeError(\"activation should be relu/gelu, not %s.\" % activation)\n",
    "\n",
    "def _get_clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n",
    "\n",
    "def subsequent_mask(size):\n",
    "    \n",
    "    attn_shape = (1, size, size)\n",
    "    mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    return torch.from_numpy(mask) == 0\n",
    "\n",
    "def _generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1).to(device)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "class MultiheadAttention(nn.Module):\n",
    "    \n",
    "    __constants__ = ['q_proj_weight', 'k_proj_weight', 'v_proj_weight', 'in_proj_weight']\n",
    "\n",
    "    def __init__(self, embed_dim, num_heads, dropout=0., bias=True, add_bias_kv=False, add_zero_attn=False, kdim=None,\n",
    "                 vdim=None):\n",
    "        super(MultiheadAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.kdim = kdim if kdim is not None else embed_dim\n",
    "        self.vdim = vdim if vdim is not None else embed_dim\n",
    "        self._qkv_same_embed_dim = self.kdim == embed_dim and self.vdim == embed_dim\n",
    "\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = dropout\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "        assert self.head_dim * num_heads == self.embed_dim, \"embed_dim must be divisible by num_heads\"\n",
    "\n",
    "        if self._qkv_same_embed_dim is False:\n",
    "            self.q_proj_weight = nn.Parameter(torch.Tensor(embed_dim, embed_dim))\n",
    "            self.k_proj_weight = nn.Parameter(torch.Tensor(embed_dim, self.kdim))\n",
    "            self.v_proj_weight = nn.Parameter(torch.Tensor(embed_dim, self.vdim))\n",
    "            self.register_parameter('in_proj_weight', None)\n",
    "        else:\n",
    "            self.in_proj_weight = nn.Parameter(torch.empty(3 * embed_dim, embed_dim))\n",
    "            self.register_parameter('q_proj_weight', None)\n",
    "            self.register_parameter('k_proj_weight', None)\n",
    "            self.register_parameter('v_proj_weight', None)\n",
    "\n",
    "        if bias:\n",
    "            self.in_proj_bias = nn.Parameter(torch.empty(3 * embed_dim))\n",
    "        else:\n",
    "            self.register_parameter('in_proj_bias', None)\n",
    "        self.out_proj = nn.Linear(embed_dim, embed_dim, bias=bias)\n",
    "\n",
    "        if add_bias_kv:\n",
    "            self.bias_k = nn.Parameter(torch.empty(1, 1, embed_dim))\n",
    "            self.bias_v = nn.Parameter(torch.empty(1, 1, embed_dim))\n",
    "        else:\n",
    "            self.bias_k = self.bias_v = None\n",
    "\n",
    "        self.add_zero_attn = add_zero_attn\n",
    "\n",
    "        self._reset_parameters()\n",
    "\n",
    "    def _reset_parameters(self):\n",
    "        if self._qkv_same_embed_dim:\n",
    "            nn.init.xavier_uniform_(self.in_proj_weight)\n",
    "        else:\n",
    "            nn.init.xavier_uniform_(self.q_proj_weight)\n",
    "            nn.init.xavier_uniform_(self.k_proj_weight)\n",
    "            nn.init.xavier_uniform_(self.v_proj_weight)\n",
    "\n",
    "        if self.in_proj_bias is not None:\n",
    "            nn.init.constant_(self.in_proj_bias, 0.)\n",
    "            nn.init.constant_(self.out_proj.bias, 0.)\n",
    "        if self.bias_k is not None:\n",
    "            nn.init.xavier_normal_(self.bias_k)\n",
    "        if self.bias_v is not None:\n",
    "            nn.init.xavier_normal_(self.bias_v)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        \n",
    "        if '_qkv_same_embed_dim' not in state:\n",
    "            state['_qkv_same_embed_dim'] = True\n",
    "\n",
    "        super(MultiheadAttention, self).__setstate__(state)\n",
    "\n",
    "    def forward(self, query, key, value, key_padding_mask=None,\n",
    "                need_weights=True, attn_mask=None):\n",
    "        \n",
    "        if not self._qkv_same_embed_dim:\n",
    "            return multi_head_attention_forward(\n",
    "                query, key, value, self.embed_dim, self.num_heads,\n",
    "                self.in_proj_weight, self.in_proj_bias,\n",
    "                self.bias_k, self.bias_v, self.add_zero_attn,\n",
    "                self.dropout, self.out_proj.weight, self.out_proj.bias,\n",
    "                training=self.training,\n",
    "                key_padding_mask=key_padding_mask, need_weights=need_weights,\n",
    "                attn_mask=attn_mask, use_separate_proj_weight=True,\n",
    "                q_proj_weight=self.q_proj_weight, k_proj_weight=self.k_proj_weight,\n",
    "                v_proj_weight=self.v_proj_weight)\n",
    "        else:\n",
    "            return multi_head_attention_forward(\n",
    "                query, key, value, self.embed_dim, self.num_heads,\n",
    "                self.in_proj_weight, self.in_proj_bias,\n",
    "                self.bias_k, self.bias_v, self.add_zero_attn,\n",
    "                self.dropout, self.out_proj.weight, self.out_proj.bias,\n",
    "                training=self.training,\n",
    "                key_padding_mask=key_padding_mask, need_weights=need_weights,\n",
    "                attn_mask=attn_mask)\n",
    "\n",
    "\n",
    "class TransformerEncoderLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0, activation=\"relu\"):\n",
    "        super(TransformerEncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiheadAttention(d_model, nhead, dropout=dropout)\n",
    "        \n",
    "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.activation = _get_activation_fn(activation)\n",
    "\n",
    "    def forward(self, src, src_mask=None, src_key_padding_mask=None):\n",
    "        \n",
    "        src2, attn = self.self_attn(src, src, src, attn_mask=src_mask,\n",
    "                                    key_padding_mask=src_key_padding_mask)\n",
    "        src = src + self.dropout1(src2)\n",
    "        src = self.norm1(src)\n",
    "\n",
    "        if hasattr(self, \"activation\"):\n",
    "            src2 = self.linear2(self.dropout(self.activation(self.linear1(src))))\n",
    "        else:\n",
    "            src2 = self.linear2(self.dropout(F.relu(self.linear1(src))))\n",
    "\n",
    "        src = src + self.dropout2(src2)\n",
    "        src = self.norm2(src)\n",
    "        return src, attn\n",
    "\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder_layer, num_layers, norm=None):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.layers = _get_clones(encoder_layer, num_layers)\n",
    "        self.num_layers = num_layers\n",
    "        self.norm = norm\n",
    "\n",
    "    def forward(self, src, mask=None, src_key_padding_mask=None):\n",
    "        \n",
    "        output = src\n",
    "\n",
    "        atts = []\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            output, attn = self.layers[i](output, src_mask=mask,\n",
    "                                          src_key_padding_mask=src_key_padding_mask)\n",
    "            atts.append(attn)\n",
    "        if self.norm:\n",
    "            output = self.norm(output)\n",
    "\n",
    "        return output, atts\n",
    "\n",
    "class TransformerDecoderLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0, activation=\"relu\"):\n",
    "        super(TransformerDecoderLayer, self).__init__()\n",
    "        self.tgt_attn = MultiheadAttention(d_model, nhead, dropout=dropout)\n",
    "        self.src_attn = MultiheadAttention(d_model, nhead, dropout=dropout)\n",
    "        \n",
    "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "\n",
    "        self.activation = _get_activation_fn(activation)\n",
    "\n",
    "    def forward(self, src, target, src_mask=None, target_mask=None, src_key_padding_mask=None):\n",
    "        \n",
    "        target2, attn_tgt = self.tgt_attn(target, target, target, attn_mask=target_mask,\n",
    "                                    key_padding_mask=src_key_padding_mask)\n",
    "        target = target+self.dropout1(target2)\n",
    "        target = self.norm1(target)\n",
    "        \n",
    "        target2, attn_src = self.src_attn(target, src, src, attn_mask=src_mask,\n",
    "                                    key_padding_mask=src_key_padding_mask)\n",
    "        target = target + self.dropout2(target2)\n",
    "        target = self.norm2(target)\n",
    "\n",
    "        if hasattr(self, \"activation\"):\n",
    "            target2 = self.linear2(self.dropout(self.activation(self.linear1(target))))\n",
    "        else:\n",
    "            target2 = self.linear2(self.dropout(F.relu(self.linear1(target))))\n",
    "\n",
    "        target = target + self.dropout3(target2)\n",
    "        target = self.norm3(target)\n",
    "        return target, attn_tgt, attn_src\n",
    "    \n",
    "class TransformerDecoder(nn.Module):\n",
    "\n",
    "    def __init__(self, decoder_layer, num_layers, norm=None):\n",
    "        super(TransformerDecoder, self).__init__()\n",
    "        self.layers = _get_clones(decoder_layer, num_layers)\n",
    "        self.num_layers = num_layers\n",
    "        self.norm = norm\n",
    "\n",
    "    def forward(self, src, target, src_mask=None, target_mask=None, src_key_padding_mask=None):\n",
    "\n",
    "        atts_tgt = []\n",
    "        atts_src = []\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            target, attn_tgt, attn_src = self.layers[i](src, target, src_mask=src_mask,target_mask = target_mask,\n",
    "                                          src_key_padding_mask=src_key_padding_mask)\n",
    "            atts_tgt.append(attn_tgt)\n",
    "            atts_src.append(attn_src)\n",
    "        if self.norm:\n",
    "            target = self.norm(target)\n",
    "\n",
    "        return target, atts_tgt, atts_src\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import argparse\n",
    "\n",
    "import time\n",
    "import math\n",
    "import scipy.io as scp\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image, ImageOps\n",
    "from scipy.ndimage.interpolation import rotate\n",
    "\n",
    "import io\n",
    "\n",
    "from multiprocessing import Pool\n",
    "import torch.multiprocessing\n",
    "\n",
    "def construct_target(phy_tgt, traj, num_queries):\n",
    "    for k in range(phy_tgt.shape[1]):\n",
    "        traj_input = traj[:, k, :, :2]\n",
    "        da_x = (traj_input[:, -1, 0] - traj_input[:, -2, 0]) / 1\n",
    "        da_y = (traj_input[:, -1, 1] - traj_input[:, -2, 1]) / 1\n",
    "        new_da_x = da_x-da_x\n",
    "        new_da_y = da_y\n",
    "    \n",
    "        hist_outputs = torch.zeros([traj.shape[0], 12, 2]).to(device)\n",
    "        for i in range(hist_outputs.shape[0]):\n",
    "            hist_outputs[i, :, 0] = torch.linspace(traj_input[i, -1, 0].item(),\n",
    "                                                       traj_input[i, -1, 0].item() + new_da_x[i].item() * 12, 13)[1:]\n",
    "            hist_outputs[i, :, 1] = torch.linspace(traj_input[i, -1, 1].item(),\n",
    "                                                       traj_input[i, -1, 1].item() + new_da_y[i].item() * 12, 13)[1:]\n",
    "        \n",
    "        phy_tgt[:, k, 0, :, :] = hist_outputs\n",
    "        phy_tgt = phy_tgt.to(device)\n",
    "    return phy_tgt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-enlargement",
   "metadata": {},
   "outputs": [],
   "source": [
    "#global interactor: refer to Z. Zhou, L. Ye, J. Wang, K. Wu, and K. Lu. \"HiVT: Hierarchical vector Transformer for multi-agent motion prediction,\" In Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), New Orleans, Louisiana, USA, pp. 8823-8833, Jun. 2022\n",
    "\n",
    "from typing import List, Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def init_weights(m: nn.Module) -> None:\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, (nn.Conv1d, nn.Conv2d, nn.Conv3d)):\n",
    "        fan_in = m.in_channels / m.groups\n",
    "        fan_out = m.out_channels / m.groups\n",
    "        bound = (6.0 / (fan_in + fan_out)) ** 0.5\n",
    "        nn.init.uniform_(m.weight, -bound, bound)\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, nn.Embedding):\n",
    "        nn.init.normal_(m.weight, mean=0.0, std=0.02)\n",
    "    elif isinstance(m, (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d)):\n",
    "        nn.init.ones_(m.weight)\n",
    "        nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, nn.LayerNorm):\n",
    "        nn.init.ones_(m.weight)\n",
    "        nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, nn.MultiheadAttention):\n",
    "        if m.in_proj_weight is not None:\n",
    "            fan_in = m.embed_dim\n",
    "            fan_out = m.embed_dim\n",
    "            bound = (6.0 / (fan_in + fan_out)) ** 0.5\n",
    "            nn.init.uniform_(m.in_proj_weight, -bound, bound)\n",
    "        else:\n",
    "            nn.init.xavier_uniform_(m.q_proj_weight)\n",
    "            nn.init.xavier_uniform_(m.k_proj_weight)\n",
    "            nn.init.xavier_uniform_(m.v_proj_weight)\n",
    "        if m.in_proj_bias is not None:\n",
    "            nn.init.zeros_(m.in_proj_bias)\n",
    "        nn.init.xavier_uniform_(m.out_proj.weight)\n",
    "        if m.out_proj.bias is not None:\n",
    "            nn.init.zeros_(m.out_proj.bias)\n",
    "        if m.bias_k is not None:\n",
    "            nn.init.normal_(m.bias_k, mean=0.0, std=0.02)\n",
    "        if m.bias_v is not None:\n",
    "            nn.init.normal_(m.bias_v, mean=0.0, std=0.02)\n",
    "    elif isinstance(m, nn.LSTM):\n",
    "        for name, param in m.named_parameters():\n",
    "            if 'weight_ih' in name:\n",
    "                for ih in param.chunk(4, 0):\n",
    "                    nn.init.xavier_uniform_(ih)\n",
    "            elif 'weight_hh' in name:\n",
    "                for hh in param.chunk(4, 0):\n",
    "                    nn.init.orthogonal_(hh)\n",
    "            elif 'weight_hr' in name:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "            elif 'bias_ih' in name:\n",
    "                nn.init.zeros_(param)\n",
    "            elif 'bias_hh' in name:\n",
    "                nn.init.zeros_(param)\n",
    "                nn.init.ones_(param.chunk(4, 0)[1])\n",
    "    elif isinstance(m, nn.GRU):\n",
    "        for name, param in m.named_parameters():\n",
    "            if 'weight_ih' in name:\n",
    "                for ih in param.chunk(3, 0):\n",
    "                    nn.init.xavier_uniform_(ih)\n",
    "            elif 'weight_hh' in name:\n",
    "                for hh in param.chunk(3, 0):\n",
    "                    nn.init.orthogonal_(hh)\n",
    "            elif 'bias_ih' in name:\n",
    "                nn.init.zeros_(param)\n",
    "            elif 'bias_hh' in name:\n",
    "                nn.init.zeros_(param)\n",
    "\n",
    "class MultipleInputEmbedding(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels: List[int],\n",
    "                 out_channel: int) -> None:\n",
    "        super(MultipleInputEmbedding, self).__init__()\n",
    "        self.module_list = nn.ModuleList(\n",
    "            [nn.Sequential(nn.Linear(in_channel, out_channel),\n",
    "                           nn.LayerNorm(out_channel),\n",
    "                           nn.ReLU(inplace=True),\n",
    "                           nn.Linear(out_channel, out_channel))\n",
    "             for in_channel in in_channels])\n",
    "        self.aggr_embed = nn.Sequential(\n",
    "            nn.LayerNorm(out_channel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(out_channel, out_channel),\n",
    "            nn.LayerNorm(out_channel))\n",
    "        self.apply(init_weights)\n",
    "\n",
    "    def forward(self,\n",
    "                continuous_inputs: List[torch.Tensor],\n",
    "                categorical_inputs: Optional[List[torch.Tensor]] = None) -> torch.Tensor:\n",
    "        for i in range(len(self.module_list)):\n",
    "            continuous_inputs[i] = self.module_list[i](continuous_inputs[i])\n",
    "        output = torch.stack(continuous_inputs).sum(dim=0)\n",
    "        if categorical_inputs is not None:\n",
    "            output += torch.stack(categorical_inputs).sum(dim=0)\n",
    "        return self.aggr_embed(output)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.typing import Adj\n",
    "from torch_geometric.typing import OptTensor\n",
    "from torch_geometric.typing import Size\n",
    "from torch_geometric.utils import softmax\n",
    "from torch_geometric.utils import subgraph\n",
    "\n",
    "from itertools import permutations\n",
    "\n",
    "class GlobalInteractorLayer(MessagePassing):\n",
    "\n",
    "    def __init__(self,\n",
    "                 embed_dim: int,\n",
    "                 num_heads: int = 8,\n",
    "                 dropout: float = 0.1,\n",
    "                 **kwargs) -> None:\n",
    "        super(GlobalInteractorLayer, self).__init__(aggr='add', node_dim=0, **kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.lin_q_node = nn.Linear(embed_dim, embed_dim)\n",
    "        self.lin_k_node = nn.Linear(embed_dim, embed_dim)\n",
    "        self.lin_k_edge = nn.Linear(embed_dim, embed_dim)\n",
    "        self.lin_v_node = nn.Linear(embed_dim, embed_dim)\n",
    "        self.lin_v_edge = nn.Linear(embed_dim, embed_dim)\n",
    "        self.lin_self = nn.Linear(embed_dim, embed_dim)\n",
    "        self.attn_drop = nn.Dropout(dropout)\n",
    "        self.lin_ih = nn.Linear(embed_dim, embed_dim)\n",
    "        self.lin_hh = nn.Linear(embed_dim, embed_dim)\n",
    "        self.out_proj = nn.Linear(embed_dim, embed_dim)\n",
    "        self.proj_drop = nn.Dropout(dropout)\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim * 4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(embed_dim * 4, embed_dim),\n",
    "            nn.Dropout(dropout))\n",
    "\n",
    "    def forward(self,\n",
    "                x: torch.Tensor,\n",
    "                edge_index: Adj,\n",
    "                edge_attr: torch.Tensor,\n",
    "                size: Size = None) -> torch.Tensor:\n",
    "        x = x + self._mha_block(self.norm1(x), edge_index, edge_attr, size)\n",
    "        x = x + self._ff_block(self.norm2(x))\n",
    "        return x\n",
    "\n",
    "    def message(self,\n",
    "                x_i: torch.Tensor,\n",
    "                x_j: torch.Tensor,\n",
    "                edge_attr: torch.Tensor,\n",
    "                index: torch.Tensor,\n",
    "                ptr: OptTensor,\n",
    "                size_i: Optional[int]) -> torch.Tensor:\n",
    "        query = self.lin_q_node(x_i).view(-1, self.num_heads, self.embed_dim // self.num_heads)\n",
    "        key_node = self.lin_k_node(x_j).view(-1, self.num_heads, self.embed_dim // self.num_heads)\n",
    "        key_edge = self.lin_k_edge(edge_attr).view(-1, self.num_heads, self.embed_dim // self.num_heads)\n",
    "        value_node = self.lin_v_node(x_j).view(-1, self.num_heads, self.embed_dim // self.num_heads)\n",
    "        value_edge = self.lin_v_edge(edge_attr).view(-1, self.num_heads, self.embed_dim // self.num_heads)\n",
    "        scale = (self.embed_dim // self.num_heads) ** 0.5\n",
    "        alpha = (query * (key_node + key_edge)).sum(dim=-1) / scale\n",
    "        alpha = softmax(alpha, index, ptr, size_i)\n",
    "        alpha = self.attn_drop(alpha)\n",
    "        return (value_node + value_edge) * alpha.unsqueeze(-1)\n",
    "\n",
    "    def update(self,\n",
    "               inputs: torch.Tensor,\n",
    "               x: torch.Tensor) -> torch.Tensor:\n",
    "        inputs = inputs.view(-1, self.embed_dim)\n",
    "        gate = torch.sigmoid(self.lin_ih(inputs) + self.lin_hh(x))\n",
    "        return inputs + gate * (self.lin_self(x) - inputs)\n",
    "\n",
    "    def _mha_block(self,\n",
    "                   x: torch.Tensor,\n",
    "                   edge_index: Adj,\n",
    "                   edge_attr: torch.Tensor,\n",
    "                   size: Size) -> torch.Tensor:\n",
    "        x = self.out_proj(self.propagate(edge_index=edge_index, x=x, edge_attr=edge_attr, size=size))\n",
    "        return self.proj_drop(x)\n",
    "\n",
    "    def _ff_block(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.mlp(x)\n",
    "\n",
    "class GlobalInteractor(nn.Module):\n",
    "    def __init__(self,\n",
    "                 historical_steps: int,\n",
    "                 embed_dim: int,\n",
    "                 edge_dim: int,\n",
    "                 num_modes: int = 1,\n",
    "                 num_heads: int = 8,\n",
    "                 num_layers: int = 3,\n",
    "                 dropout: float = 0.1) -> None:\n",
    "        super(GlobalInteractor, self).__init__()\n",
    "        self.historical_steps = historical_steps\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_modes = num_modes\n",
    "\n",
    "        self.rel_embed = MultipleInputEmbedding(in_channels=[edge_dim, edge_dim], out_channel=embed_dim)\n",
    "        self.global_interactor_layers = nn.ModuleList(\n",
    "            [GlobalInteractorLayer(embed_dim=embed_dim, num_heads=num_heads, dropout=dropout)\n",
    "             for _ in range(num_layers)])\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "        self.multihead_proj = nn.Linear(embed_dim, num_modes * embed_dim)\n",
    "        self.apply(init_weights)\n",
    "        \n",
    "    def forward(self,data,social_inp) -> torch.Tensor:\n",
    "        \n",
    "        social_out = torch.zeros([0,social_inp.shape[1],social_inp.shape[2]]).to(device)\n",
    "        for m in range(social_inp.shape[0]):\n",
    "            temp_inp = social_inp[m,:,:]\n",
    "            num_nodes = data['VALID_LEN'][m,0].item()\n",
    "            if num_nodes==1:\n",
    "                #social_out = torch.cat([social_out,torch.zeros([1,social_inp.shape[1],social_inp.shape[2]])],dim=0)\n",
    "                social_out = torch.cat([social_out,social_inp[[m],:,:]],dim=0)\n",
    "                continue\n",
    "            temp_edge_index = torch.LongTensor(list(permutations(range(num_nodes), 2))).t().contiguous().to(device)\n",
    "            temp_norm_center = data['NORM_CENTER'][m,:]\n",
    "            temp_heading = data['HEADINGS'][m]\n",
    "            \n",
    "            temp_rel_pos = temp_norm_center[temp_edge_index[0]] - temp_norm_center[temp_edge_index[1]]\n",
    "            temp_rel_theta = temp_heading[temp_edge_index[0]] - temp_heading[temp_edge_index[1]]\n",
    "            temp_rel_theta_cos = torch.cos(temp_rel_theta)\n",
    "            temp_rel_theta_sin = torch.sin(temp_rel_theta)\n",
    "            temp_rel_embed = self.rel_embed([temp_rel_pos, torch.cat((temp_rel_theta_cos, temp_rel_theta_sin), dim=-1)])\n",
    "            \n",
    "            x = temp_inp\n",
    "            for layer in self.global_interactor_layers:\n",
    "                x = layer(x,temp_edge_index,temp_rel_embed)\n",
    "            x = self.norm(x)  \n",
    "            x = self.multihead_proj(x).view(-1,self.num_modes,self.embed_dim)  \n",
    "            x = x.transpose(0,1)  \n",
    "            social_out = torch.cat([social_out,x],dim=0)\n",
    "        \n",
    "        return social_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conditional-setting",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiPredictionHeader(nn.Module):\n",
    "    def __init__(self, d_model, out_size, dropout, reg_h_dim=128, dis_h_dim=128, cls_h_dim=128):\n",
    "        super(MultiPredictionHeader, self).__init__()\n",
    "        self.out_size = out_size\n",
    "        self.reg_mlp_veh = nn.Sequential(\n",
    "            nn.Linear(d_model, reg_h_dim * 2, bias=True),\n",
    "            nn.LayerNorm(reg_h_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(reg_h_dim * 2, reg_h_dim, bias=True),\n",
    "            nn.Linear(reg_h_dim, out_size, bias=True))\n",
    "        self.reg_mlp_bic = nn.Sequential(\n",
    "            nn.Linear(d_model, reg_h_dim * 2, bias=True),\n",
    "            nn.LayerNorm(reg_h_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(reg_h_dim * 2, reg_h_dim, bias=True),\n",
    "            nn.Linear(reg_h_dim, out_size, bias=True))\n",
    "        self.reg_mlp_ped = nn.Sequential(\n",
    "            nn.Linear(d_model, reg_h_dim * 2, bias=True),\n",
    "            nn.LayerNorm(reg_h_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(reg_h_dim * 2, reg_h_dim, bias=True),\n",
    "            nn.Linear(reg_h_dim, out_size, bias=True))\n",
    "        self.fusion3 = nn.Linear(4, 2, bias=True)\n",
    "        self.fusion4 = nn.Linear(4, 2, bias=True)\n",
    "        self.num_modes = 1\n",
    "        \n",
    "    def forward(self, feature_out,data,traj):\n",
    "        \n",
    "        pred = torch.zeros([*feature_out.shape[:2],self.out_size]).to(device)\n",
    "\n",
    "        pred[data['CLASS_LIST']==1] = self.reg_mlp_veh(feature_out[data['CLASS_LIST']==1])\n",
    "        pred[data['CLASS_LIST']==2] = self.reg_mlp_bic(feature_out[data['CLASS_LIST']==2])\n",
    "        pred[data['CLASS_LIST']==3] = self.reg_mlp_ped(feature_out[data['CLASS_LIST']==3])\n",
    "        \n",
    "        ori_pred = pred.view(*pred.shape[:-1], -1, 2)\n",
    "        pred = ori_pred.cumsum(dim=-2)\n",
    "        \n",
    "        fusion_phy = torch.zeros([pred.shape[0],pred.shape[1],1,12,2]).to(device)\n",
    "        fusion_phy = construct_target(fusion_phy,traj,self.num_modes)\n",
    "        \n",
    "        hist_outputs = fusion_phy.squeeze(2)\n",
    "        hist = hist_outputs.cumsum(axis=-2)\n",
    "        \n",
    "        final_cum = self.fusion3(torch.cat([pred, hist], -1))\n",
    "        final_ori = self.fusion4(torch.cat([ori_pred, hist_outputs], -1))\n",
    "        \n",
    "        return final_cum, final_ori\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-tablet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer_utils refer to Y. Liu, J. Zhang, L. Fang, Q. Jiang, and B. Zhou, \"Multimodal motion prediction with stacked transformers,\" In Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), virtually, pp. 7577-7586, Jun. 2021\n",
    "\n",
    "from Transformer_utils import (Decoder, DecoderLayer, Encoder, EncoderDecoder,\n",
    "                                 EncoderLayer, LinearEmbedding, MultiHeadAttention,\n",
    "                                 PointerwiseFeedforward, PositionalEncoding,\n",
    "                                 SublayerConnection)\n",
    "\n",
    "class MA_STTN_MAP(nn.Module):\n",
    "    def __init__(self, hist_inp_size, num_queries, dec_inp_size, dec_out_size, N, N_social,\n",
    "                d_model, d_ff, pos_dim, dist_dim, h, dropout):\n",
    "        super(MA_STTN_MAP, self).__init__()\n",
    "        self.num_queries = num_queries\n",
    "        c = copy.deepcopy\n",
    "        dropout_atten = dropout\n",
    "        attn = MultiHeadAttention(h, d_model, dropout=dropout_atten)\n",
    "        ff = PointerwiseFeedforward(d_model, d_ff, dropout)\n",
    "        position = PositionalEncoding(d_model, dropout)\n",
    "        \n",
    "        self.hist_tf = EncoderDecoder(\n",
    "            Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n",
    "            Decoder(DecoderLayer(d_model, c(attn), c(attn), c(ff), dropout), N),\n",
    "            nn.Sequential(LinearEmbedding(hist_inp_size, d_model), c(position)))\n",
    "        self.lane_enc = Encoder(EncoderLayer(\n",
    "            d_model, c(attn), c(ff), dropout), N_lane)\n",
    "        self.lane_dec = Decoder(DecoderLayer(\n",
    "            d_model, c(attn), c(attn), c(ff), dropout), N_lane)\n",
    "        self.lane_emb = LinearEmbedding(lane_inp_size, d_model)\n",
    "        self.phy_emb = nn.Sequential(\n",
    "            nn.Flatten(start_dim=-2,end_dim=-1),\n",
    "            nn.Linear(12*2, d_model, bias=True),\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model, d_model, bias=True))\n",
    "        self.pos_emb = nn.Sequential(\n",
    "            nn.Linear(2, pos_dim, bias=True),\n",
    "            nn.LayerNorm(pos_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(pos_dim, pos_dim, bias=True))\n",
    "        self.dist_emb = nn.Sequential(\n",
    "            nn.Linear(num_queries*d_model, dist_dim, bias=True),\n",
    "            nn.LayerNorm(dist_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dist_dim, dist_dim, bias=True))\n",
    "        \n",
    "        self.fusion1 = nn.Sequential(\n",
    "            nn.Linear(d_model+pos_dim, d_model, bias=True),\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model, d_model, bias=True))\n",
    "        self.fusion2 = nn.Sequential(\n",
    "            nn.Linear(dist_dim+pos_dim, d_model, bias=True),\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model, d_model, bias=True))\n",
    "        self.fusion3 = nn.Linear(4, 2, bias=True)\n",
    "        self.fusion4 = nn.Linear(4, 2, bias=True)\n",
    "        self.social_enc = Encoder(EncoderLayer(\n",
    "            d_model, c(attn), c(ff), dropout), N_social)\n",
    "        self.social_dec = Decoder(DecoderLayer(\n",
    "            d_model, c(attn), c(attn), c(ff), dropout), N_social)\n",
    "        \n",
    "        self.historical_steps = 8\n",
    "        self.edge_dim = 2\n",
    "        self.embed_dim = d_model\n",
    "        self.num_modes = num_queries\n",
    "        self.num_heads = 8\n",
    "        self.num_global_layers = 3\n",
    "        self.global_interactor = GlobalInteractor(historical_steps=self.historical_steps,\n",
    "                                    embed_dim=self.embed_dim,\n",
    "                                    edge_dim=self.edge_dim,\n",
    "                                    num_modes=self.num_modes,\n",
    "                                    num_heads=self.num_heads,\n",
    "                                    num_layers=self.num_global_layers,\n",
    "                                    dropout=dropout).to(device)\n",
    "        \n",
    "        self.w1 = nn.Parameter(torch.FloatTensor(1), requires_grad=True)\n",
    "        self.w2 = nn.Parameter(torch.FloatTensor(1), requires_grad=True)\n",
    "        self.w3 = nn.Parameter(torch.FloatTensor(1), requires_grad=True)\n",
    "        self.theta = nn.Parameter(torch.FloatTensor(1), requires_grad=False)\n",
    "\n",
    "        self.w1.data.fill_(3**0.5)\n",
    "        self.w2.data.fill_(3**0.5)\n",
    "        self.w3.data.fill_(3**0.5)\n",
    "        self.theta.data.fill_(0.9)\n",
    "        \n",
    "        for name, param in self.named_parameters():\n",
    "            # print(name)\n",
    "            if param.dim() > 1:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "\n",
    "        self.query_embed = nn.Embedding(self.num_queries, d_model)\n",
    "        self.query_embed.weight.requires_grad == True\n",
    "        nn.init.orthogonal_(self.query_embed.weight)\n",
    "        \n",
    "        \n",
    "    def forward(self, traj, pos, max_agent_num, social_mask,lane_vec, lane_mask,data):\n",
    "        self.query_batches = self.query_embed.weight.view(\n",
    "            1, 1, *self.query_embed.weight.shape).repeat(*traj.shape[:2], 1, 1)\n",
    "        # Physics target construction\n",
    "        phy_tgt = torch.zeros([self.query_batches.shape[0],self.query_batches.shape[1],self.query_batches.shape[2],12,2]).to(device)\n",
    "        phy_tgt = construct_target(phy_tgt,traj,self.num_queries)\n",
    "        phy_tgt = self.phy_emb(phy_tgt)\n",
    "        \n",
    "        #historical information\n",
    "        hist_out = self.hist_tf(traj, phy_tgt, None, None, self.query_batches)\n",
    "        pos = self.pos_emb(pos)\n",
    "        hist_out = torch.cat([pos.unsqueeze(dim=2).repeat(\n",
    "                    1, 1, self.num_queries, 1), hist_out], dim=-1)\n",
    "        hist_out = self.fusion1(hist_out)\n",
    "        \n",
    "        #lane encoder\n",
    "        social_num = max_agent_num\n",
    "        lane_mem = self.lane_enc(self.lane_emb(lane_vec), lane_mask)\n",
    "        lane_mem = lane_mem.unsqueeze(1).repeat(1, social_num, 1, 1)\n",
    "        lane_mask = lane_mask.unsqueeze(1).repeat(1, social_num, 1, 1)\n",
    "        \n",
    "        # Lane decoder\n",
    "        lane_out = self.lane_dec(hist_out, lane_mem, lane_mask, None)\n",
    "        \n",
    "        # Fuse position information\n",
    "        dist = lane_out.view(*traj.shape[0:2], -1)\n",
    "        dist = self.dist_emb(dist)\n",
    "        \n",
    "        #Global Interactor\n",
    "        social_inp = self.fusion2(torch.cat([pos, dist], -1))\n",
    "        social_out = self.global_interactor(data,social_inp)\n",
    "        \n",
    "        feature_out = torch.cat([social_out,lane_out.squeeze(2),phy_tgt.squeeze(2)], -1)\n",
    "        \n",
    "        return feature_out\n",
    "    \n",
    "    def cal_traj_loss_dann(self,loss_traj_s1,loss_traj_s2,loss_traj_s3):\n",
    "        return (1/(self.w1)**2)*loss_traj_s1+(1/(self.w2)**2)*loss_traj_s2+(1/(self.w3)**2)*loss_traj_s3+\\\n",
    "                torch.log(self.w1+torch.Tensor([1.0]).to(device))+torch.log(self.w2+torch.Tensor([1.0]).to(device))+torch.log(self.w3+torch.Tensor([1.0]).to(device))\n",
    "    \n",
    "    def cal_total_loss_dann(self,loss_traj_s1,loss_traj_s2,loss_traj_s3,\n",
    "                          loss_domain_s1,loss_domain_s2,loss_domain_s3):\n",
    "        traj_loss = (1/(self.w1)**2)*loss_traj_s1+(1/(self.w2)**2)*loss_traj_s2+(1/(self.w3)**2)*loss_traj_s3+\\\n",
    "                    torch.log(self.w1+torch.Tensor([1.0]).to(device))+torch.log(self.w2+torch.Tensor([1.0]).to(device))+torch.log(self.w3+torch.Tensor([1.0]).to(device))\n",
    "        \n",
    "        domain_loss = (1/(self.w1)**2)*loss_domain_s1+(1/(self.w2)**2)*loss_domain_s2+(1/(self.w3)**2)*loss_domain_s3+\\\n",
    "                    torch.log(self.w1+torch.Tensor([1.0]).to(device))+torch.log(self.w2+torch.Tensor([1.0]).to(device))+torch.log(self.w3+torch.Tensor([1.0]).to(device))\n",
    "        \n",
    "        total_loss = self.theta*traj_loss + (torch.Tensor([1.0]).to(device)-self.theta)*domain_loss\n",
    "        return total_loss,traj_loss,domain_loss\n",
    "    \n",
    "    def cal_total_loss_target(self,loss_traj_t,loss_domain_t):\n",
    "        \n",
    "        total_loss = self.theta*loss_traj_t + (torch.Tensor([1.0]).to(device)-self.theta)*loss_domain_t\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-change",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.init as init\n",
    "from torch.nn import Parameter\n",
    "\n",
    "class GradReverse(torch.autograd.Function):\n",
    "\n",
    "    def forward(ctx, x, constant):\n",
    "        ctx.constant = constant\n",
    "        return x.view_as(x)\n",
    "\n",
    "    def backward(ctx, grad_output):\n",
    "        grad_output = grad_output.neg() * ctx.constant\n",
    "        return grad_output, None\n",
    "\n",
    "    def grad_reverse(x, constant):\n",
    "        return GradReverse.apply(x, constant)\n",
    "\n",
    "class Domain_D(nn.Module):\n",
    "\n",
    "    def __init__(self,d_model):\n",
    "        super(Domain_D, self).__init__()\n",
    "        self.classify = nn.Sequential(\n",
    "                nn.Linear(d_model*3, 512, bias=True),\n",
    "                #nn.LayerNorm(reg_h_dim * 2),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                nn.Linear(512, 256, bias=True),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                nn.Linear(256, 1, bias=True))\n",
    "\n",
    "    def forward(self,inputs):\n",
    "        \n",
    "        logits = self.classify(inputs)\n",
    "\n",
    "        return logits\n",
    "    \n",
    "class TrajectoryAttentionMechanism(nn.Module):\n",
    "    def __init__(self,fin,d_model,fout,N_domain,h_domain,d_ff,dropout_domain):\n",
    "        \n",
    "        super(TrajectoryAttentionMechanism,self).__init__()\n",
    "        c = copy.deepcopy\n",
    "        domain_attn = MultiHeadAttention(h_domain, d_model*3, dropout=dropout_domain)\n",
    "        domain_ff = PointerwiseFeedforward(d_model*3, d_ff, dropout_domain)\n",
    "        self.domain_enc = Encoder(EncoderLayer(d_model*3, c(domain_attn), c(domain_ff), dropout_domain), N_domain)\n",
    "        \n",
    "        \n",
    "    def forward(self,feature_out,social_mask):\n",
    "        D_inputs = self.domain_enc(feature_out, social_mask)\n",
    "        \n",
    "        return D_inputs[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-broadcasting",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameter\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#HTN feature extractor\n",
    "hist_inp_size = 5\n",
    "num_queries = 1\n",
    "lane_inp_size = 64\n",
    "dec_inp_size = 64\n",
    "# output steps*2: 12*2\n",
    "dec_out_size = 24\n",
    "N = 2\n",
    "N_lane = 2\n",
    "N_social = 2\n",
    "d_model = 128\n",
    "d_ff = 256\n",
    "pos_dim = 64\n",
    "dist_dim = 128\n",
    "h = 4\n",
    "dropout = 0.1\n",
    "PredictionModel = MA_STTN_MAP(hist_inp_size, num_queries, dec_inp_size, dec_out_size, N, N_social, d_model, d_ff, pos_dim, dist_dim, h, dropout).to(device)\n",
    "\n",
    "#LaneNet for trajectory preprocessing\n",
    "lane_channels= 4\n",
    "subgraph_width = 32\n",
    "num_subgraph_layres =2\n",
    "lane_subgraph = LaneNet(lane_channels, subgraph_width, num_subgraph_layres).to(device)\n",
    "\n",
    "#Trajectory prediction header\n",
    "prediction_header = MultiPredictionHeader(d_model*3, dec_out_size, dropout).to(device)\n",
    "\n",
    "#domain discriminator\n",
    "dropout_domain = 0.1\n",
    "N_domain = 2\n",
    "h_domain = 4\n",
    "d_model = 128\n",
    "d_ff = 256\n",
    "fin = d_model*3\n",
    "fout = 1\n",
    "TraAttM = TrajectoryAttentionMechanism(fin,d_model,fout,N_domain,h_domain,d_ff,dropout_domain).to(device)\n",
    "\n",
    "domain_dis = Domain_D(d_model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-shape",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guassian_kernel(source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n",
    "\n",
    "    n_samples = int(source.size()[0])+int(target.size()[0])\n",
    "    total = torch.cat([source, target], dim=0)\n",
    "    total0 = total.unsqueeze(0).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n",
    "    total1 = total.unsqueeze(1).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n",
    "    L2_distance = ((total0-total1)**2).sum(2) \n",
    "    if fix_sigma:\n",
    "        bandwidth = fix_sigma\n",
    "    else:\n",
    "        bandwidth = torch.sum(L2_distance.data) / (n_samples**2-n_samples)\n",
    "    bandwidth /= kernel_mul ** (kernel_num // 2)\n",
    "    bandwidth_list = [bandwidth * (kernel_mul**i) for i in range(kernel_num)]\n",
    "    kernel_val = [torch.exp(-L2_distance / bandwidth_temp) for bandwidth_temp in bandwidth_list]\n",
    "    return sum(kernel_val)\n",
    "\n",
    "def cal_mmd(source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n",
    "    \n",
    "    batch_size = int(source.size()[0])\n",
    "    kernels = guassian_kernel(source, target,\n",
    "        kernel_mul=kernel_mul, kernel_num=kernel_num, fix_sigma=fix_sigma)\n",
    "    XX = kernels[:batch_size, :batch_size]\n",
    "    YY = kernels[batch_size:, batch_size:]\n",
    "    XY = kernels[:batch_size, batch_size:]\n",
    "    YX = kernels[batch_size:, :batch_size]\n",
    "    loss = torch.mean(XX + YY - XY -YX)\n",
    "    return loss\n",
    "\n",
    "import torch.autograd as autograd\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
    "lambda_gp = 10\n",
    "\n",
    "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
    "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
    "    # Random weight term for interpolation between real and fake samples\n",
    "    alpha = Tensor(np.random.random((real_samples.size(0), 1)))\n",
    "    # Get random interpolation between real and fake samples\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "    d_interpolates = D(interpolates)\n",
    "    fake = Variable(Tensor(real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "    # Get gradient w.r.t. interpolates\n",
    "    gradients = autograd.grad(\n",
    "        outputs=d_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=fake,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True,\n",
    "    )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty\n",
    "\n",
    "def cal_train_loss(traj_lab,outputs_coord,labels_mask):\n",
    "    muX = outputs_coord[:,:,:,[0]].to(device)\n",
    "    muY = outputs_coord[:,:,:,[1]].to(device)\n",
    "    x = traj_lab[:,:,:,[0]].to(device)\n",
    "    y = traj_lab[:,:,:,[1]].to(device)\n",
    "    each_err = torch.sqrt(torch.pow(x - muX, 2) + torch.pow(y - muY, 2))\n",
    "    sum_target_err = torch.sum(each_err,dim=2)\n",
    "    error_mask = torch.floor(torch.sum(labels_mask,dim=2)/12)\n",
    "    if torch.sum(error_mask)==0:\n",
    "        return torch.tensor([0.])\n",
    "    train_error = torch.sum(torch.mul(sum_target_err,error_mask))/(torch.sum(error_mask)*12)\n",
    "    return train_error\n",
    "\n",
    "def cal_metric(traj_lab,outputs_coord,labels_mask):\n",
    "    muX = outputs_coord[:,:,:,[0]].to(device)\n",
    "    muY = outputs_coord[:,:,:,[1]].to(device)\n",
    "    x = traj_lab[:,:,:,[0]].to(device)\n",
    "    y = traj_lab[:,:,:,[1]].to(device)\n",
    "    each_err = torch.sqrt(torch.pow(x - muX, 2) + torch.pow(y - muY, 2))\n",
    "    mean_target_err = torch.mean(each_err,dim=2)\n",
    "    final_target_err = each_err[:,:,-1,:]\n",
    "    error_mask = torch.floor(torch.sum(labels_mask,dim=2)/12)\n",
    "    if torch.sum(error_mask)==0:\n",
    "        return torch.tensor([0.]),torch.tensor([0.])\n",
    "    mean_error = torch.sum(torch.mul(mean_target_err,error_mask))/(torch.sum(error_mask))\n",
    "    final_error = torch.sum(torch.mul(final_target_err,error_mask))/(torch.sum(error_mask))\n",
    "    return mean_error,final_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transparent-outline",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss=[]\n",
    "val_loss=[]\n",
    "validation_loss=[]\n",
    "\n",
    "from torch.nn import functional as f\n",
    "\n",
    "def get_input_data(data,lane_subgraph):\n",
    "    B = data['HISTORY'].shape[0]\n",
    "    pos = data['NORM_CENTER']\n",
    "    traj = data['HISTORY']\n",
    "    lane = data['NEW_LANES']\n",
    "    traj_valid_len = data['VALID_LEN'][:,0]\n",
    "    max_agent_num = torch.max(traj_valid_len)\n",
    "    lane_valid_len = data['VALID_LEN'][:,1]\n",
    "    max_lane_num = torch.max(lane_valid_len)\n",
    "    \n",
    "    social_mask = preprocess_traj(data['HISTORY'],B,traj_valid_len,max_agent_num)\n",
    "    lane_vec, lane_mask = preprocess_lane(lane_subgraph,lane,B,lane_valid_len,max_lane_num)\n",
    "    \n",
    "    traj_lab = torch.zeros((0,data['FUTURE'].shape[1],12,2)).to(device)\n",
    "    labels = torch.zeros((0,data['FUTURE'].shape[1],12,2)).to(device)\n",
    "    for i in range(len(data['FUTURE'])):\n",
    "        gt = data['FUTURE'][i,:,:,:2].unsqueeze(0)\n",
    "        labels = torch.cat([labels,gt],dim=0)\n",
    "        gt = gt.cumsum(axis=-2)\n",
    "        traj_lab = torch.cat([traj_lab,gt],dim=0)\n",
    "    labels_mask = data['FUTURE'][:,:,:,[-1]]\n",
    "    \n",
    "    traj,pos,max_agent_num,social_mask,lane_vec,lane_mask,traj_lab,labels_mask = \\\n",
    "            Variable(traj.to(device)),Variable(pos.to(device)),Variable(max_agent_num.to(device)),\\\n",
    "            Variable(social_mask.to(device)),Variable(lane_vec.to(device)),Variable(lane_mask.to(device)),\\\n",
    "            Variable(traj_lab.to(device)),Variable(labels_mask.to(device))\n",
    "    \n",
    "    return traj,pos,max_agent_num,social_mask,lane_vec,lane_mask,traj_lab,labels_mask\n",
    "\n",
    "def train_model(PredictionModel,prediction_header,lane_subgraph,TraAttM,domain_dis,p_optimizer,d_optimizer,num_epochs,log_interval=25,scheduler=None):\n",
    "    since = time.time()\n",
    "    best_prediction_model_wts = copy.deepcopy(PredictionModel.state_dict())\n",
    "    best_prediction_header_wts = copy.deepcopy(prediction_header.state_dict())\n",
    "    best_lane_subgraph_wts = copy.deepcopy(lane_subgraph.state_dict())\n",
    "    best_TraAttM_wts = copy.deepcopy(TraAttM.state_dict())\n",
    "    best_domain_dis_wts = copy.deepcopy(domain_dis.state_dict())\n",
    "    \n",
    "    best_loss = 100\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        iteration = 0\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                PredictionModel.train()\n",
    "                lane_subgraph.train()\n",
    "                prediction_header.train()\n",
    "                TraAttM.train()\n",
    "                domain_dis.train()\n",
    "\n",
    "                start_steps = epoch * dataset_sizes['train_s']\n",
    "                total_steps = 50 * dataset_sizes['train_s']\n",
    "                \n",
    "                running_loss = 0.0\n",
    "                \n",
    "                for batch_idx, (sdata1, sdata2, sdata3) in enumerate(zip(dataloaders['train_s1'],dataloaders['train_s2'],dataloaders['train_s3'])):\n",
    "                    traj_s1,pos_s1,max_agent_num_s1,social_mask_s1,lane_vec_s1,lane_mask_s1,traj_lab_s1,labels_mask_s1 = get_input_data(sdata1,lane_subgraph)\n",
    "                    traj_s2,pos_s2,max_agent_num_s2,social_mask_s2,lane_vec_s2,lane_mask_s2,traj_lab_s2,labels_mask_s2 = get_input_data(sdata2,lane_subgraph)\n",
    "                    traj_s3,pos_s3,max_agent_num_s3,social_mask_s3,lane_vec_s3,lane_mask_s3,traj_lab_s3,labels_mask_s3 = get_input_data(sdata3,lane_subgraph)\n",
    "                    #traj_t,pos_t,max_agent_num_t,social_mask_t,lane_vec_t,lane_mask_t,traj_lab_t,labels_mask_t = get_input_data(tdata,lane_subgraph)\n",
    "                        \n",
    "                    B = traj_s1.shape[0]\n",
    "\n",
    "                    # setup optimizer\n",
    "                    d_optimizer.zero_grad()\n",
    "                    p_optimizer.zero_grad()\n",
    "                        \n",
    "                    feature_out_s1 = PredictionModel(traj_s1,pos_s1,max_agent_num_s1,social_mask_s1,lane_vec_s1,lane_mask_s1,sdata1)\n",
    "                    feature_out_s2 = PredictionModel(traj_s2,pos_s2,max_agent_num_s2,social_mask_s2,lane_vec_s2,lane_mask_s2,sdata2)\n",
    "                    feature_out_s3 = PredictionModel(traj_s3,pos_s3,max_agent_num_s3,social_mask_s3,lane_vec_s3,lane_mask_s3,sdata3)\n",
    "                    #feature_out_t = PredictionModel(traj_t,pos_t,max_agent_num_t,social_mask_t,lane_vec_t,lane_mask_t,tdata)\n",
    "\n",
    "                    pred_cum_s1,pred_ori_s1 = prediction_header(feature_out_s1,sdata1,traj_s1)\n",
    "                    pred_cum_s2,pred_ori_s2 = prediction_header(feature_out_s2,sdata2,traj_s2)\n",
    "                    pred_cum_s3,pred_ori_s3 = prediction_header(feature_out_s3,sdata3,traj_s3)\n",
    "                    #pred_cum_t,pred_ori_t = prediction_header(feature_out_t,tdata,traj_t)\n",
    "                        \n",
    "                    D_inputs_s1 = TraAttM(feature_out_s1,social_mask_s1)\n",
    "                    D_inputs_s2 = TraAttM(feature_out_s2,social_mask_s2)\n",
    "                    D_inputs_s3 = TraAttM(feature_out_s3,social_mask_s3)\n",
    "                    #D_inputs_t = TraAttM(feature_out_t,social_mask_t)\n",
    "                    \n",
    "                    fake_inputs_t = np.random.laplace(0, 1, size=D_inputs_s1.shape).astype('float32')\n",
    "                    fake_inputs_t  = torch.tensor(fake_inputs_t).to(device)\n",
    "                    \n",
    "                    D_pred_s1 = domain_dis(D_inputs_s1)\n",
    "                    D_pred_s2 = domain_dis(D_inputs_s2)\n",
    "                    D_pred_s3 = domain_dis(D_inputs_s3)\n",
    "                    #D_pred_t = domain_dis(D_inputs_t)\n",
    "                    D_pred_t = domain_dis(fake_inputs_t)\n",
    "                    \n",
    "                    #mmd loss calculation\n",
    "                    mmd_s12 = cal_mmd(D_inputs_s1,D_inputs_s2)\n",
    "                    mmd_s13 = cal_mmd(D_inputs_s1,D_inputs_s3)\n",
    "                    mmd_s23 = cal_mmd(D_inputs_s2,D_inputs_s3)\n",
    "                    \n",
    "                    gradient_penalty_s1 = compute_gradient_penalty(domain_dis, fake_inputs_t, D_inputs_s1)\n",
    "                    gradient_penalty_s2 = compute_gradient_penalty(domain_dis, fake_inputs_t, D_inputs_s2)\n",
    "                    gradient_penalty_s3 = compute_gradient_penalty(domain_dis, fake_inputs_t, D_inputs_s3)\n",
    "                    \n",
    "                    D_loss_s1 = torch.mean(D_pred_t)-torch.mean(D_pred_s1)+lambda_gp*gradient_penalty_s1\n",
    "                    D_loss_s2 = torch.mean(D_pred_t)-torch.mean(D_pred_s2)+lambda_gp*gradient_penalty_s2\n",
    "                    D_loss_s3 = torch.mean(D_pred_t)-torch.mean(D_pred_s3)+lambda_gp*gradient_penalty_s3\n",
    "                    #discriminator loss\n",
    "                    train_D_loss = (D_loss_s1+D_loss_s2+D_loss_s3)/12\n",
    "                    train_D_loss.backward(retain_graph=True)\n",
    "                    \n",
    "                    G_loss_s1 = (-torch.mean(D_pred_t)+torch.mean(D_pred_s1))/(12/3)\n",
    "                    G_loss_s2 = (-torch.mean(D_pred_t)+torch.mean(D_pred_s2))/(12/3)\n",
    "                    G_loss_s3 = (-torch.mean(D_pred_t)+torch.mean(D_pred_s3))/(12/3)\n",
    "                    \n",
    "                    loss_traj_s1 = cal_train_loss(traj_lab_s1,pred_cum_s1,labels_mask_s1)\n",
    "                    loss_traj_s2 = cal_train_loss(traj_lab_s2,pred_cum_s2,labels_mask_s2)\n",
    "                    loss_traj_s3 = cal_train_loss(traj_lab_s3,pred_cum_s3,labels_mask_s3)\n",
    "                    \n",
    "                    traj_loss = PredictionModel.cal_traj_loss_dann(loss_traj_s1,loss_traj_s2,loss_traj_s3)\n",
    "                    train_P_loss = traj_loss+(G_loss_s1+G_loss_s2+G_loss_s3)/3+mmd_s12+mmd_s13+mmd_s23\n",
    "                    train_P_loss.backward()\n",
    "                    d_optimizer.step()\n",
    "                    p_optimizer.step()\n",
    "                    \n",
    "                    running_loss += train_P_loss.item() * B\n",
    "                    \n",
    "                    if batch_idx % log_interval == 0:\n",
    "                            print('Train Epoch: {} [{}/{} ({:.1f}%)] P Loss: {:.6f} Traj Loss: {:.6f} D Loss: {:.6f} mmd: {:.6f} w1:{:.6f} w2:{:.6f} w3:{:.6f}'.format(\n",
    "                    epoch, batch_idx * B, dataset_sizes['train_s'],batch_idx * B/dataset_sizes['train_s']*100,train_P_loss.item(),traj_loss.item(),train_D_loss.item()\\\n",
    "                            ,(mmd_s12.item()+mmd_s13.item()+mmd_s23.item())/3,PredictionModel.w1[0].item(),PredictionModel.w2[0].item(),PredictionModel.w3[0].item()))\n",
    "                    \n",
    "                epoch_loss = running_loss / dataset_sizes['train_s']\n",
    "                \n",
    "            elif phase == 'val':\n",
    "                PredictionModel.eval()\n",
    "                lane_subgraph.eval()\n",
    "                prediction_header.eval()\n",
    "                TraAttM.eval()\n",
    "                domain_dis.eval()\n",
    "                \n",
    "                running_loss = 0.0\n",
    "                show_model_error_mean = 0.0\n",
    "                show_model_error_final = 0.0\n",
    "                show_model_error_mean_s1 = 0.0\n",
    "                show_model_error_final_s1 = 0.0\n",
    "                show_model_error_mean_s2 = 0.0\n",
    "                show_model_error_final_s2 = 0.0\n",
    "                show_model_error_mean_s3 = 0.0\n",
    "                show_model_error_final_s3 = 0.0\n",
    "                \n",
    "                for batch_idx, (sdata1, sdata2, sdata3, tdata) in enumerate(zip(dataloaders['val_s1'],dataloaders['val_s2'],\n",
    "                    dataloaders['val_s3'],dataloaders['val_t'])):\n",
    "                    \n",
    "                    traj_s1,pos_s1,max_agent_num_s1,social_mask_s1,lane_vec_s1,lane_mask_s1,traj_lab_s1,labels_mask_s1 = get_input_data(sdata1,lane_subgraph)\n",
    "                    traj_s2,pos_s2,max_agent_num_s2,social_mask_s2,lane_vec_s2,lane_mask_s2,traj_lab_s2,labels_mask_s2 = get_input_data(sdata2,lane_subgraph)\n",
    "                    traj_s3,pos_s3,max_agent_num_s3,social_mask_s3,lane_vec_s3,lane_mask_s3,traj_lab_s3,labels_mask_s3 = get_input_data(sdata3,lane_subgraph)\n",
    "                    traj_t,pos_t,max_agent_num_t,social_mask_t,lane_vec_t,lane_mask_t,traj_lab_t,labels_mask_t = get_input_data(tdata,lane_subgraph)\n",
    "                    \n",
    "                    B = traj_s1.shape[0]\n",
    "                    \n",
    "                    feature_out_s1 = PredictionModel(traj_s1,pos_s1,max_agent_num_s1,social_mask_s1,lane_vec_s1,lane_mask_s1,sdata1)\n",
    "                    feature_out_s2 = PredictionModel(traj_s2,pos_s2,max_agent_num_s2,social_mask_s2,lane_vec_s2,lane_mask_s2,sdata2)\n",
    "                    feature_out_s3 = PredictionModel(traj_s3,pos_s3,max_agent_num_s3,social_mask_s3,lane_vec_s3,lane_mask_s3,sdata3)\n",
    "                    feature_out_t = PredictionModel(traj_t,pos_t,max_agent_num_t,social_mask_t,lane_vec_t,lane_mask_t,tdata)\n",
    "                    \n",
    "                    pred_cum_s1,pred_ori_s1 = prediction_header(feature_out_s1,sdata1,traj_s1)\n",
    "                    pred_cum_s2,pred_ori_s2 = prediction_header(feature_out_s2,sdata2,traj_s2)\n",
    "                    pred_cum_s3,pred_ori_s3 = prediction_header(feature_out_s3,sdata3,traj_s3)\n",
    "                    pred_cum_t,pred_ori_t = prediction_header(feature_out_t,tdata,traj_t)\n",
    "                    \n",
    "                    loss_traj_s1 = cal_train_loss(traj_lab_s1,pred_cum_s1,labels_mask_s1)\n",
    "                    vali_mean_s1, vali_final_s1 = cal_metric(traj_lab_s1,pred_cum_s1,labels_mask_s1)\n",
    "                    loss_traj_s2 = cal_train_loss(traj_lab_s2,pred_cum_s2,labels_mask_s2)\n",
    "                    vali_mean_s2, vali_final_s2 = cal_metric(traj_lab_s2,pred_cum_s2,labels_mask_s2)\n",
    "                    loss_traj_s3 = cal_train_loss(traj_lab_s3,pred_cum_s3,labels_mask_s3)\n",
    "                    vali_mean_s3, vali_final_s3 = cal_metric(traj_lab_s3,pred_cum_s3,labels_mask_s3)\n",
    "                        \n",
    "                    traj_loss = PredictionModel.cal_traj_loss_dann(loss_traj_s1,loss_traj_s2,loss_traj_s3)\n",
    "                    \n",
    "                    vali_mean, vali_final = cal_metric(traj_lab_t,pred_cum_t,labels_mask_t)\n",
    "                    \n",
    "                    show_model_error_mean += vali_mean.item() * B\n",
    "                    show_model_error_final += vali_final.item() * B\n",
    "                    \n",
    "                    running_loss += traj_loss.item() * B\n",
    "                    show_model_error_mean_s1 += vali_mean_s1.item() * B\n",
    "                    show_model_error_final_s1 += vali_final_s1.item() * B\n",
    "                    show_model_error_mean_s2 += vali_mean_s2.item() * B\n",
    "                    show_model_error_final_s2 += vali_final_s2.item() * B\n",
    "                    show_model_error_mean_s3 += vali_mean_s3.item() * B\n",
    "                    show_model_error_final_s3 += vali_final_s3.item() * B\n",
    "                #domain_correct = tgt_correct + src_correct1 + src_correct2 + src_correct3\n",
    "    \n",
    "                epoch_loss = running_loss / dataset_sizes['val_s']\n",
    "                epoch_show_loss_mean_s1 = show_model_error_mean_s1 / dataset_sizes['val_s']\n",
    "                epoch_show_loss_final_s1 = show_model_error_final_s1 / dataset_sizes['val_s']\n",
    "                epoch_show_loss_mean_s2 = show_model_error_mean_s2 / dataset_sizes['val_s']\n",
    "                epoch_show_loss_final_s2 = show_model_error_final_s2 / dataset_sizes['val_s']\n",
    "                epoch_show_loss_mean_s3 = show_model_error_mean_s3 / dataset_sizes['val_s']\n",
    "                epoch_show_loss_final_s3 = show_model_error_final_s3 / dataset_sizes['val_s']\n",
    "                epoch_show_loss_mean = show_model_error_mean / dataset_sizes['val_s']\n",
    "                epoch_show_loss_final = show_model_error_final / dataset_sizes['val_s']\n",
    "                val_loss.append(epoch_loss)\n",
    "                print('{} Loss: {:.6f} Source 1 Mean_Error: {:.6f} Source 1 Final_Error {:.6f} Source 2 Mean_Error: {:.6f} Source 2 Final_Error {:.6f} Source 3 Mean_Error: {:.6f} Source 3 Final_Error {:.6f}'\\\n",
    "                      .format('val',epoch_loss,epoch_show_loss_mean_s1,epoch_show_loss_final_s1,epoch_show_loss_mean_s2,epoch_show_loss_final_s2,epoch_show_loss_mean_s3,epoch_show_loss_final_s3))\n",
    "                print('{} Mean_Error: {:.6f} Final_Error {:.6f}'.format('Target Val Error :',epoch_show_loss_mean,epoch_show_loss_final))\n",
    "                \n",
    "                if epoch_loss < best_loss:\n",
    "                    best_loss = epoch_loss\n",
    "                    best_prediction_model_wts = copy.deepcopy(PredictionModel.state_dict())\n",
    "                    best_prediction_header_wts = copy.deepcopy(prediction_header.state_dict())\n",
    "                    best_lane_subgraph_wts = copy.deepcopy(lane_subgraph.state_dict())\n",
    "                    best_TraAttM_wts = copy.deepcopy(TraAttM.state_dict())\n",
    "                    best_domain_dis_wts = copy.deepcopy(domain_dis.state_dict())\n",
    "                    torch.save(PredictionModel.state_dict(), r'PredictionModel_DG_intersectionA(%d).tar' %(epoch+1))\n",
    "                    torch.save(prediction_header.state_dict(), r'prediction_header_DG_intersectionA(%d).tar' %(epoch+1))\n",
    "                    torch.save(lane_subgraph.state_dict(), r'lane_subgraph_DG_intersectionA(%d).tar' %(epoch+1))\n",
    "                    torch.save(TraAttM.state_dict(), r'TraAttM_DG_intersectionA(%d).tar' %(epoch+1))\n",
    "                    torch.save(domain_dis.state_dict(), r'domain_dis_DG_intersectionA(%d).tar' %(epoch+1))\n",
    "    \n",
    "    if(scheduler):\n",
    "        scheduler.step()\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:8f}'.format(best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    torch.save(PredictionModel.state_dict(), r'PredictionModel_DG_intersectionA(Final).tar')\n",
    "    torch.save(prediction_header.state_dict(), r'prediction_header_DG_intersectionA(Final).tar')\n",
    "    torch.save(lane_subgraph.state_dict(), r'lane_subgraph_DG_intersectionA(Final).tar')\n",
    "    torch.save(TraAttM.state_dict(), r'TraAttM_DG_intersectionA(Final).tar')\n",
    "    torch.save(domain_dis.state_dict(), r'domain_dis_DG_intersectionA(Final).tar')\n",
    "    \n",
    "    PredictionModel.load_state_dict(best_prediction_model_wts)\n",
    "    prediction_header.load_state_dict(best_prediction_header_wts)\n",
    "    lane_subgraph.load_state_dict(best_lane_subgraph_wts)\n",
    "    TraAttM.load_state_dict(best_TraAttM_wts)\n",
    "    domain_dis.load_state_dict(best_domain_dis_wts)\n",
    "    torch.save(PredictionModel.state_dict(), r'PredictionModel_DG_intersectionA.tar')\n",
    "    torch.save(prediction_header.state_dict(), r'prediction_header_DG_intersectionA.tar')\n",
    "    torch.save(lane_subgraph.state_dict(), r'lane_subgraph_DG_intersectionA.tar')\n",
    "    torch.save(TraAttM.state_dict(), r'TraAttM_DG_intersectionA.tar')\n",
    "    torch.save(domain_dis.state_dict(), r'domain_dis_DG_intersectionA.tar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-tobago",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import copy\n",
    "from typing import Any,Dict,List\n",
    "\n",
    "p_optimizer = torch.optim.Adam([\n",
    "        {'params': PredictionModel.parameters()},\n",
    "        {'params': lane_subgraph.parameters()},\n",
    "        {'params': prediction_header.parameters()}], lr=0.0005)\n",
    "d_optimizer = torch.optim.Adam([\n",
    "        {'params': TraAttM.parameters()},\n",
    "        {'params': domain_dis.parameters()}], lr=0.0005)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(p_optimizer, 15, gamma=0.1)\n",
    "\n",
    "train_model(PredictionModel,prediction_header,lane_subgraph,TraAttM,domain_dis,p_optimizer,d_optimizer,num_epochs=50,log_interval=100,scheduler=scheduler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-looking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_data(data,lane_subgraph):\n",
    "    B = data['HISTORY'].shape[0]\n",
    "    pos = data['NORM_CENTER']\n",
    "    traj = data['HISTORY']\n",
    "    lane = data['LANE_VECTORS']\n",
    "    traj_valid_len = data['VALID_LEN'][:,0]\n",
    "    max_agent_num = torch.max(traj_valid_len)\n",
    "    lane_valid_len = data['VALID_LEN'][:,1]\n",
    "    max_lane_num = torch.max(lane_valid_len)\n",
    "    \n",
    "    social_mask = preprocess_traj(data['HISTORY'],B,traj_valid_len,max_agent_num)\n",
    "    lane_vec, lane_mask = preprocess_lane(lane_subgraph,lane,B,lane_valid_len,max_lane_num)\n",
    "    \n",
    "    traj_lab = torch.zeros((0,data['FUTURE'].shape[1],12,2)).to(device)\n",
    "    labels = torch.zeros((0,data['FUTURE'].shape[1],12,2)).to(device)\n",
    "    for i in range(len(data['FUTURE'])):\n",
    "        gt = data['FUTURE'][i,:,:,:2].unsqueeze(0)\n",
    "        labels = torch.cat([labels,gt],dim=0)\n",
    "        gt = gt.cumsum(axis=-2)\n",
    "        traj_lab = torch.cat([traj_lab,gt],dim=0)\n",
    "    labels_mask = data['FUTURE'][:,:,:,[-1]]\n",
    "    \n",
    "    traj,pos,max_agent_num,social_mask,lane_vec,lane_mask,traj_lab,labels_mask = \\\n",
    "            Variable(traj.to(device)),Variable(pos.to(device)),Variable(max_agent_num.to(device)),\\\n",
    "            Variable(social_mask.to(device)),Variable(lane_vec.to(device)),Variable(lane_mask.to(device)),\\\n",
    "            Variable(traj_lab.to(device)),Variable(labels_mask.to(device))\n",
    "    \n",
    "    return traj,pos,max_agent_num,social_mask,lane_vec,lane_mask,traj_lab,labels_mask\n",
    "\n",
    "def cal_test_metric(traj_lab,outputs_coord,labels_mask):\n",
    "    muX = outputs_coord[:,:,:,[0]].to(device)\n",
    "    muY = outputs_coord[:,:,:,[1]].to(device)\n",
    "    x = traj_lab[:,:,:,[0]].to(device)\n",
    "    y = traj_lab[:,:,:,[1]].to(device)\n",
    "    each_err = torch.sqrt(torch.pow(x - muX, 2) + torch.pow(y - muY, 2))\n",
    "    #mean_target_err = torch.mean(each_err,dim=2)\n",
    "    #final_target_err = each_err[:,:,-1,:]\n",
    "    error_mask = torch.floor(torch.sum(labels_mask,dim=2)/12)\n",
    "    err_mean = torch.zeros([4])\n",
    "    err_final = torch.zeros([4])\n",
    "    if torch.sum(error_mask)==0:\n",
    "        return err_mean,err_final\n",
    "    for i in range(4):\n",
    "        mean_target_err = torch.mean(each_err[:,:,:3*(i+1),:],dim=2)\n",
    "        final_target_err = each_err[:,:,3*(i+1)-1,:]\n",
    "        mean_error = torch.sum(torch.mul(mean_target_err,error_mask))/(torch.sum(error_mask))\n",
    "        final_error = torch.sum(torch.mul(final_target_err,error_mask))/(torch.sum(error_mask))\n",
    "        err_mean[i] = mean_error\n",
    "        err_final[i] = final_error\n",
    "    return err_mean,err_final\n",
    "\n",
    "def cal_RFDE(outputs,labels):\n",
    "    muX = outputs[:,:,[0]]\n",
    "    muY = outputs[:,:,[1]]\n",
    "    x = labels[:,:,[0]]\n",
    "    y = labels[:,:,[1]]\n",
    "    out =  torch.sqrt(torch.pow(x - muX, 2) + torch.pow(y - muY, 2))\n",
    "    lossSum = torch.sum(out[:,:,0],dim=0)\n",
    "    err_final_rela_son = torch.zeros([4])\n",
    "    err_final_rela_mom = torch.zeros([4])\n",
    "    for i in range(4):\n",
    "        err_final_rela_son[i] = lossSum[3*(i+1)-1]\n",
    "        err_final_rela_mom[i] = torch.sum(torch.sqrt(torch.pow(labels[:,3*(i+1)-1,[0]], 2) + torch.pow(labels[:,3*(i+1)-1,[1]], 2)))\n",
    "        \n",
    "    return err_final_rela_son,err_final_rela_mom\n",
    "\n",
    "PredictionModel.eval()   # Set model to evaluate mode\n",
    "prediction_header.eval()\n",
    "lane_subgraph.eval()\n",
    "\n",
    "#running_loss = 0.0\n",
    "errors_mean = torch.zeros([4])\n",
    "errors_final = torch.zeros([4])\n",
    "errors_final_son = torch.zeros([4])\n",
    "errors_final_mom = torch.zeros([4])\n",
    "\n",
    "for batch_idx,data in enumerate(dataloaders['test_t']):\n",
    "    \n",
    "    traj,pos,max_agent_num,social_mask,lane_vec,lane_mask,traj_lab,labels_mask = get_input_data(data,lane_subgraph)\n",
    "    B = traj.shape[0]\n",
    "    \n",
    "    feature_out = PredictionModel(traj,pos,max_agent_num,social_mask,lane_vec,lane_mask,data)\n",
    "    pred_cum,pred_ori = prediction_header(feature_out,data,traj)\n",
    "    #train_P_loss = cal_train_loss(traj_lab_t,pred_cum_t,labels_mask_t)\n",
    "    #vali_mean, vali_final = cal_metric(traj_lab_t,pred_cum_t,labels_mask_t)\n",
    "    err_mean, err_final = cal_test_metric(traj_lab,pred_cum,labels_mask)\n",
    "    \n",
    "    #running_loss += train_P_loss.item() * B\n",
    "    errors_mean += (err_mean*B).detach().numpy()\n",
    "    errors_final += (err_final*B).detach().numpy()\n",
    "    #domain_correct = tgt_correct + src_correct1 + src_correct2 + src_correct3\n",
    "    \n",
    "    error_mask = torch.floor(torch.sum(labels_mask,dim=2)/12)\n",
    "    remain_cum = pred_cum[error_mask[:,:,0]==1,:,:]\n",
    "    remain_traj_lab = traj_lab[error_mask[:,:,0]==1,:,:]\n",
    "    \n",
    "    err_final_rela_son,err_final_rela_mom = cal_RFDE(remain_cum,remain_traj_lab)\n",
    "    errors_final_son += (err_final_rela_son).detach().numpy()\n",
    "    errors_final_mom += (err_final_rela_mom).detach().numpy()\n",
    "    \n",
    "#epoch_loss = running_loss / dataset_sizes['test_t']\n",
    "errors_mean = errors_mean / dataset_sizes['test_t']\n",
    "errors_final = errors_final / dataset_sizes['test_t']\n",
    "print('Target Mean Error(m) :',errors_mean)\n",
    "print('Target Final Error(m) :',errors_final)\n",
    "print('Target RFDE :',errors_final_son/errors_final_mom)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

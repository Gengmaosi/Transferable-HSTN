{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-brazilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import copy\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from typing import Any,Dict,List\n",
    "\n",
    "padding_keys = ['HISTORY','FUTURE','NORM_CENTER','LANE_VECTORS','NEW_LANES','CLASS_LIST']\n",
    "stacking_keys = ['VALID_LEN']\n",
    "listing_keys = ['TARGET_MASK','LANE_ID','HEADINGS','RAW_HISTORY','RAW_FUTURE']\n",
    "\n",
    "def collate_single_cpu(batch):\n",
    "\n",
    "    keys = batch[0].keys()\n",
    "\n",
    "    out = {k: [] for k in keys}\n",
    "\n",
    "    for data in batch:\n",
    "        for k, v in data.items():\n",
    "            out[k].append(v)\n",
    "    \n",
    "    # stacking\n",
    "    for k in stacking_keys:\n",
    "        out[k] = torch.stack(out[k], dim=0)\n",
    "    \n",
    "    # padding\n",
    "    for k in padding_keys:\n",
    "        out[k] = pad_sequence(out[k], batch_first=True)\n",
    "    \n",
    "    return out\n",
    "\n",
    "class inDDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        super(inDDataset, self).__init__()\n",
    "\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        data_dict = self.get_data(idx)\n",
    "\n",
    "        return data_dict\n",
    "\n",
    "    def get_data(self, idx):\n",
    "        \n",
    "        out_dict = {}\n",
    "        \n",
    "        datadict = self.data[idx]\n",
    "        out_dict.update(datadict)\n",
    "\n",
    "        for k, v in out_dict.items():\n",
    "            if isinstance(v, np.ndarray):\n",
    "                v = torch.from_numpy(v).to(device)\n",
    "            \n",
    "                if v.dtype == torch.double:\n",
    "                    v = v.type(torch.float32).to(device)\n",
    "            \n",
    "                out_dict[k] = v\n",
    "\n",
    "        return out_dict\n",
    "\n",
    "def pad_track(\n",
    "        track_df: pd.DataFrame,\n",
    "        seq_timestamps: np.ndarray,\n",
    "        base: int,\n",
    "        track_len: int,\n",
    "        raw_data_format: Dict[str, int],\n",
    ") -> np.ndarray:\n",
    "    \n",
    "    track_vals = track_df.values\n",
    "    track_timestamps = track_df['frame'].values\n",
    "    seq_timestamps = seq_timestamps[base:base+track_len]\n",
    "\n",
    "    start_idx = np.where(seq_timestamps == track_timestamps[0])[0][0]\n",
    "    end_idx = np.where(seq_timestamps == track_timestamps[-1])[0][0]\n",
    "\n",
    "    padded_track_array = np.pad(track_vals,\n",
    "                                ((start_idx, track_len - end_idx - 1),\n",
    "                                    (0, 0)), \"edge\")\n",
    "\n",
    "    mask = np.ones((end_idx+1-start_idx))\n",
    "    mask = np.pad(mask, (start_idx, track_len - end_idx - 1), 'constant')\n",
    "    if padded_track_array.shape[0] < track_len:\n",
    "        return None, None, False\n",
    "\n",
    "    for i in range(padded_track_array.shape[0]):\n",
    "        padded_track_array[i, 0] = seq_timestamps[i]\n",
    "    assert mask.shape[0] == padded_track_array.shape[0]\n",
    "    return padded_track_array, mask, True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-pressure",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "processed_data_path = r'intersectionA_data_with_map.pkl'\n",
    "\n",
    "with open(processed_data_path, 'rb') as f:\n",
    "    total_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominican-interpretation",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_indices = np.random.permutation(len(total_data))\n",
    "train_indices = shuffled_indices[:int(len(total_data)*0.8)]\n",
    "val_indices = shuffled_indices[int(len(total_data)*0.8):int(len(total_data)*0.9)]\n",
    "test_indices = shuffled_indices[int(len(total_data)*0.9):]\n",
    "\n",
    "train_data = []\n",
    "val_data = []\n",
    "test_data = []\n",
    "for ind in train_indices:\n",
    "    train_data.append(total_data[ind])\n",
    "for ind in val_indices:\n",
    "    val_data.append(total_data[ind])\n",
    "for ind in test_indices:\n",
    "    test_data.append(total_data[ind])\n",
    "\n",
    "train_Dataset = inDDataset(train_data)\n",
    "train_dataloader = DataLoader(train_Dataset,shuffle=True,batch_size=32,num_workers=0,collate_fn=collate_single_cpu)\n",
    "val_Dataset = inDDataset(val_data)\n",
    "val_dataloader = DataLoader(val_Dataset,shuffle=False,batch_size=32,num_workers=0,collate_fn=collate_single_cpu)\n",
    "test_Dataset = inDDataset(test_data)\n",
    "test_dataloader = DataLoader(test_Dataset,shuffle=False,batch_size=32,num_workers=0,collate_fn=collate_single_cpu)\n",
    "\n",
    "dataloaders = {}\n",
    "dataloaders['train'] = train_dataloader\n",
    "dataloaders['val'] = val_dataloader\n",
    "dataloaders['test'] = test_dataloader\n",
    "\n",
    "dataset_sizes = {}\n",
    "dataset_sizes['train'] = len(train_data)\n",
    "dataset_sizes['val'] = len(val_data)\n",
    "dataset_sizes['test'] = len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "periodic-ecology",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math, copy, time\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "from multi_attention_forward import multi_head_attention_forward\n",
    "\n",
    "class LaneNet(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_unit, num_subgraph_layers):\n",
    "        super(LaneNet, self).__init__()\n",
    "        self.num_subgraph_layers = num_subgraph_layers\n",
    "        self.layer_seq = nn.Sequential()\n",
    "        for i in range(num_subgraph_layers):\n",
    "            self.layer_seq.add_module(\n",
    "                f'lmlp_{i}', MLP(in_channels, hidden_unit))\n",
    "            in_channels = hidden_unit*2\n",
    "\n",
    "    def forward(self, lane):\n",
    "        \n",
    "        x = lane\n",
    "        for name, layer in self.layer_seq.named_modules():\n",
    "            if isinstance(layer, MLP):\n",
    "                x = layer(x)\n",
    "                x_max = torch.max(x, -2)[0]\n",
    "                x_max = x_max.unsqueeze(2).repeat(1, 1, x.shape[2], 1)\n",
    "                x = torch.cat([x, x_max], dim=-1)\n",
    "        x_max = torch.max(x, -2)[0]\n",
    "        return x_max\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_unit, verbose=False):\n",
    "        super(MLP, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(in_channels, hidden_unit),\n",
    "            nn.LayerNorm(hidden_unit),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mlp(x)\n",
    "        return x\n",
    "\n",
    "def preprocess_lane(lane_subgraph,lane,B, lane_valid_len, max_lane_num):\n",
    "    \n",
    "    lane_v = torch.cat(\n",
    "        [lane[:, :, :-1, :2],\n",
    "            lane[:, :, 1:, :2]], dim=-1).to(device)\n",
    "    \n",
    "    lane_mask = torch.zeros(\n",
    "        (B, 1, int(max_lane_num))).to(device)\n",
    "    for i in range(lane_valid_len.shape[0]):\n",
    "        lane_mask[i, 0, :lane_valid_len[i]] = 1\n",
    "    \n",
    "    lane_feature = lane_subgraph(lane_v)\n",
    "\n",
    "    return lane_feature, lane_mask\n",
    "\n",
    "def preprocess_traj(traj, B, traj_valid_len, max_agent_num):\n",
    "    \n",
    "    social_valid_len = traj_valid_len\n",
    "    social_mask = torch.zeros(\n",
    "        (B, 1, int(max_agent_num))).to(device)\n",
    "    for i in range(B):\n",
    "        social_mask[i, 0, :social_valid_len[i]] = 1\n",
    "\n",
    "    return social_mask\n",
    "\n",
    "\n",
    "def _get_activation_fn(activation):\n",
    "    if activation == \"relu\":\n",
    "        return F.relu\n",
    "    elif activation == \"gelu\":\n",
    "        return F.gelu\n",
    "    else:\n",
    "        raise RuntimeError(\"activation should be relu/gelu, not %s.\" % activation)\n",
    "\n",
    "def _get_clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n",
    "\n",
    "def subsequent_mask(size):\n",
    "    \n",
    "    attn_shape = (1, size, size)\n",
    "    mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    return torch.from_numpy(mask) == 0\n",
    "\n",
    "def _generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1).to(device)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "class MultiheadAttention(nn.Module):\n",
    "    \n",
    "    __constants__ = ['q_proj_weight', 'k_proj_weight', 'v_proj_weight', 'in_proj_weight']\n",
    "\n",
    "    def __init__(self, embed_dim, num_heads, dropout=0., bias=True, add_bias_kv=False, add_zero_attn=False, kdim=None,\n",
    "                 vdim=None):\n",
    "        super(MultiheadAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.kdim = kdim if kdim is not None else embed_dim\n",
    "        self.vdim = vdim if vdim is not None else embed_dim\n",
    "        self._qkv_same_embed_dim = self.kdim == embed_dim and self.vdim == embed_dim\n",
    "\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = dropout\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "        assert self.head_dim * num_heads == self.embed_dim, \"embed_dim must be divisible by num_heads\"\n",
    "\n",
    "        if self._qkv_same_embed_dim is False:\n",
    "            self.q_proj_weight = nn.Parameter(torch.Tensor(embed_dim, embed_dim))\n",
    "            self.k_proj_weight = nn.Parameter(torch.Tensor(embed_dim, self.kdim))\n",
    "            self.v_proj_weight = nn.Parameter(torch.Tensor(embed_dim, self.vdim))\n",
    "            self.register_parameter('in_proj_weight', None)\n",
    "        else:\n",
    "            self.in_proj_weight = nn.Parameter(torch.empty(3 * embed_dim, embed_dim))\n",
    "            self.register_parameter('q_proj_weight', None)\n",
    "            self.register_parameter('k_proj_weight', None)\n",
    "            self.register_parameter('v_proj_weight', None)\n",
    "\n",
    "        if bias:\n",
    "            self.in_proj_bias = nn.Parameter(torch.empty(3 * embed_dim))\n",
    "        else:\n",
    "            self.register_parameter('in_proj_bias', None)\n",
    "        self.out_proj = nn.Linear(embed_dim, embed_dim, bias=bias)\n",
    "\n",
    "        if add_bias_kv:\n",
    "            self.bias_k = nn.Parameter(torch.empty(1, 1, embed_dim))\n",
    "            self.bias_v = nn.Parameter(torch.empty(1, 1, embed_dim))\n",
    "        else:\n",
    "            self.bias_k = self.bias_v = None\n",
    "\n",
    "        self.add_zero_attn = add_zero_attn\n",
    "\n",
    "        self._reset_parameters()\n",
    "\n",
    "    def _reset_parameters(self):\n",
    "        if self._qkv_same_embed_dim:\n",
    "            nn.init.xavier_uniform_(self.in_proj_weight)\n",
    "        else:\n",
    "            nn.init.xavier_uniform_(self.q_proj_weight)\n",
    "            nn.init.xavier_uniform_(self.k_proj_weight)\n",
    "            nn.init.xavier_uniform_(self.v_proj_weight)\n",
    "\n",
    "        if self.in_proj_bias is not None:\n",
    "            nn.init.constant_(self.in_proj_bias, 0.)\n",
    "            nn.init.constant_(self.out_proj.bias, 0.)\n",
    "        if self.bias_k is not None:\n",
    "            nn.init.xavier_normal_(self.bias_k)\n",
    "        if self.bias_v is not None:\n",
    "            nn.init.xavier_normal_(self.bias_v)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        \n",
    "        if '_qkv_same_embed_dim' not in state:\n",
    "            state['_qkv_same_embed_dim'] = True\n",
    "\n",
    "        super(MultiheadAttention, self).__setstate__(state)\n",
    "\n",
    "    def forward(self, query, key, value, key_padding_mask=None,\n",
    "                need_weights=True, attn_mask=None):\n",
    "        \n",
    "        if not self._qkv_same_embed_dim:\n",
    "            return multi_head_attention_forward(\n",
    "                query, key, value, self.embed_dim, self.num_heads,\n",
    "                self.in_proj_weight, self.in_proj_bias,\n",
    "                self.bias_k, self.bias_v, self.add_zero_attn,\n",
    "                self.dropout, self.out_proj.weight, self.out_proj.bias,\n",
    "                training=self.training,\n",
    "                key_padding_mask=key_padding_mask, need_weights=need_weights,\n",
    "                attn_mask=attn_mask, use_separate_proj_weight=True,\n",
    "                q_proj_weight=self.q_proj_weight, k_proj_weight=self.k_proj_weight,\n",
    "                v_proj_weight=self.v_proj_weight)\n",
    "        else:\n",
    "            return multi_head_attention_forward(\n",
    "                query, key, value, self.embed_dim, self.num_heads,\n",
    "                self.in_proj_weight, self.in_proj_bias,\n",
    "                self.bias_k, self.bias_v, self.add_zero_attn,\n",
    "                self.dropout, self.out_proj.weight, self.out_proj.bias,\n",
    "                training=self.training,\n",
    "                key_padding_mask=key_padding_mask, need_weights=need_weights,\n",
    "                attn_mask=attn_mask)\n",
    "\n",
    "\n",
    "class TransformerEncoderLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0, activation=\"relu\"):\n",
    "        super(TransformerEncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiheadAttention(d_model, nhead, dropout=dropout)\n",
    "        \n",
    "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.activation = _get_activation_fn(activation)\n",
    "\n",
    "    def forward(self, src, src_mask=None, src_key_padding_mask=None):\n",
    "        \n",
    "        src2, attn = self.self_attn(src, src, src, attn_mask=src_mask,\n",
    "                                    key_padding_mask=src_key_padding_mask)\n",
    "        src = src + self.dropout1(src2)\n",
    "        src = self.norm1(src)\n",
    "\n",
    "        if hasattr(self, \"activation\"):\n",
    "            src2 = self.linear2(self.dropout(self.activation(self.linear1(src))))\n",
    "        else:\n",
    "            src2 = self.linear2(self.dropout(F.relu(self.linear1(src))))\n",
    "\n",
    "        src = src + self.dropout2(src2)\n",
    "        src = self.norm2(src)\n",
    "        return src, attn\n",
    "\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder_layer, num_layers, norm=None):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.layers = _get_clones(encoder_layer, num_layers)\n",
    "        self.num_layers = num_layers\n",
    "        self.norm = norm\n",
    "\n",
    "    def forward(self, src, mask=None, src_key_padding_mask=None):\n",
    "        \n",
    "        output = src\n",
    "\n",
    "        atts = []\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            output, attn = self.layers[i](output, src_mask=mask,\n",
    "                                          src_key_padding_mask=src_key_padding_mask)\n",
    "            atts.append(attn)\n",
    "        if self.norm:\n",
    "            output = self.norm(output)\n",
    "\n",
    "        return output, atts\n",
    "\n",
    "class TransformerDecoderLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0, activation=\"relu\"):\n",
    "        super(TransformerDecoderLayer, self).__init__()\n",
    "        self.tgt_attn = MultiheadAttention(d_model, nhead, dropout=dropout)\n",
    "        self.src_attn = MultiheadAttention(d_model, nhead, dropout=dropout)\n",
    "        \n",
    "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "\n",
    "        self.activation = _get_activation_fn(activation)\n",
    "\n",
    "    def forward(self, src, target, src_mask=None, target_mask=None, src_key_padding_mask=None):\n",
    "        \n",
    "        target2, attn_tgt = self.tgt_attn(target, target, target, attn_mask=target_mask,\n",
    "                                    key_padding_mask=src_key_padding_mask)\n",
    "        target = target+self.dropout1(target2)\n",
    "        target = self.norm1(target)\n",
    "        \n",
    "        target2, attn_src = self.src_attn(target, src, src, attn_mask=src_mask,\n",
    "                                    key_padding_mask=src_key_padding_mask)\n",
    "        target = target + self.dropout2(target2)\n",
    "        target = self.norm2(target)\n",
    "\n",
    "        if hasattr(self, \"activation\"):\n",
    "            target2 = self.linear2(self.dropout(self.activation(self.linear1(target))))\n",
    "        else:\n",
    "            target2 = self.linear2(self.dropout(F.relu(self.linear1(target))))\n",
    "\n",
    "        target = target + self.dropout3(target2)\n",
    "        target = self.norm3(target)\n",
    "        return target, attn_tgt, attn_src\n",
    "    \n",
    "class TransformerDecoder(nn.Module):\n",
    "\n",
    "    def __init__(self, decoder_layer, num_layers, norm=None):\n",
    "        super(TransformerDecoder, self).__init__()\n",
    "        self.layers = _get_clones(decoder_layer, num_layers)\n",
    "        self.num_layers = num_layers\n",
    "        self.norm = norm\n",
    "\n",
    "    def forward(self, src, target, src_mask=None, target_mask=None, src_key_padding_mask=None):\n",
    "\n",
    "        atts_tgt = []\n",
    "        atts_src = []\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            target, attn_tgt, attn_src = self.layers[i](src, target, src_mask=src_mask,target_mask = target_mask,\n",
    "                                          src_key_padding_mask=src_key_padding_mask)\n",
    "            atts_tgt.append(attn_tgt)\n",
    "            atts_src.append(attn_src)\n",
    "        if self.norm:\n",
    "            target = self.norm(target)\n",
    "\n",
    "        return target, atts_tgt, atts_src\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import argparse\n",
    "\n",
    "import time\n",
    "import math\n",
    "# import torch_geometric\n",
    "import scipy.io as scp\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image, ImageOps\n",
    "from scipy.ndimage.interpolation import rotate\n",
    "\n",
    "import io\n",
    "#from torch_geometric.data import Data\n",
    "#from visualizations import map_vis_xy\n",
    "\n",
    "from multiprocessing import Pool\n",
    "import torch.multiprocessing\n",
    "\n",
    "def construct_target(phy_tgt, traj, num_queries):\n",
    "    for k in range(phy_tgt.shape[1]):\n",
    "        traj_input = traj[:, k, :, :2]\n",
    "        da_x = (traj_input[:, -1, 0] - traj_input[:, -2, 0]) / 1\n",
    "        da_y = (traj_input[:, -1, 1] - traj_input[:, -2, 1]) / 1\n",
    "        new_da_x = da_x-da_x\n",
    "        new_da_y = da_y\n",
    "    \n",
    "        hist_outputs = torch.zeros([traj.shape[0], 12, 2]).to(device)\n",
    "        for i in range(hist_outputs.shape[0]):\n",
    "            hist_outputs[i, :, 0] = torch.linspace(traj_input[i, -1, 0].item(),\n",
    "                                                       traj_input[i, -1, 0].item() + new_da_x[i].item() * 12, 13)[1:]\n",
    "            hist_outputs[i, :, 1] = torch.linspace(traj_input[i, -1, 1].item(),\n",
    "                                                       traj_input[i, -1, 1].item() + new_da_y[i].item() * 12, 13)[1:]\n",
    "        \n",
    "        phy_tgt[:, k, 0, :, :] = hist_outputs\n",
    "        phy_tgt = phy_tgt.to(device)\n",
    "    return phy_tgt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressing-following",
   "metadata": {},
   "outputs": [],
   "source": [
    "#global interactor: refer to Z. Zhou, L. Ye, J. Wang, K. Wu, and K. Lu. \"HiVT: Hierarchical vector Transformer for multi-agent motion prediction,\" In Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), New Orleans, Louisiana, USA, pp. 8823-8833, Jun. 2022\n",
    "\n",
    "from typing import List, Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def init_weights(m: nn.Module) -> None:\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, (nn.Conv1d, nn.Conv2d, nn.Conv3d)):\n",
    "        fan_in = m.in_channels / m.groups\n",
    "        fan_out = m.out_channels / m.groups\n",
    "        bound = (6.0 / (fan_in + fan_out)) ** 0.5\n",
    "        nn.init.uniform_(m.weight, -bound, bound)\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, nn.Embedding):\n",
    "        nn.init.normal_(m.weight, mean=0.0, std=0.02)\n",
    "    elif isinstance(m, (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d)):\n",
    "        nn.init.ones_(m.weight)\n",
    "        nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, nn.LayerNorm):\n",
    "        nn.init.ones_(m.weight)\n",
    "        nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, nn.MultiheadAttention):\n",
    "        if m.in_proj_weight is not None:\n",
    "            fan_in = m.embed_dim\n",
    "            fan_out = m.embed_dim\n",
    "            bound = (6.0 / (fan_in + fan_out)) ** 0.5\n",
    "            nn.init.uniform_(m.in_proj_weight, -bound, bound)\n",
    "        else:\n",
    "            nn.init.xavier_uniform_(m.q_proj_weight)\n",
    "            nn.init.xavier_uniform_(m.k_proj_weight)\n",
    "            nn.init.xavier_uniform_(m.v_proj_weight)\n",
    "        if m.in_proj_bias is not None:\n",
    "            nn.init.zeros_(m.in_proj_bias)\n",
    "        nn.init.xavier_uniform_(m.out_proj.weight)\n",
    "        if m.out_proj.bias is not None:\n",
    "            nn.init.zeros_(m.out_proj.bias)\n",
    "        if m.bias_k is not None:\n",
    "            nn.init.normal_(m.bias_k, mean=0.0, std=0.02)\n",
    "        if m.bias_v is not None:\n",
    "            nn.init.normal_(m.bias_v, mean=0.0, std=0.02)\n",
    "    elif isinstance(m, nn.LSTM):\n",
    "        for name, param in m.named_parameters():\n",
    "            if 'weight_ih' in name:\n",
    "                for ih in param.chunk(4, 0):\n",
    "                    nn.init.xavier_uniform_(ih)\n",
    "            elif 'weight_hh' in name:\n",
    "                for hh in param.chunk(4, 0):\n",
    "                    nn.init.orthogonal_(hh)\n",
    "            elif 'weight_hr' in name:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "            elif 'bias_ih' in name:\n",
    "                nn.init.zeros_(param)\n",
    "            elif 'bias_hh' in name:\n",
    "                nn.init.zeros_(param)\n",
    "                nn.init.ones_(param.chunk(4, 0)[1])\n",
    "    elif isinstance(m, nn.GRU):\n",
    "        for name, param in m.named_parameters():\n",
    "            if 'weight_ih' in name:\n",
    "                for ih in param.chunk(3, 0):\n",
    "                    nn.init.xavier_uniform_(ih)\n",
    "            elif 'weight_hh' in name:\n",
    "                for hh in param.chunk(3, 0):\n",
    "                    nn.init.orthogonal_(hh)\n",
    "            elif 'bias_ih' in name:\n",
    "                nn.init.zeros_(param)\n",
    "            elif 'bias_hh' in name:\n",
    "                nn.init.zeros_(param)\n",
    "\n",
    "class MultipleInputEmbedding(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels: List[int],\n",
    "                 out_channel: int) -> None:\n",
    "        super(MultipleInputEmbedding, self).__init__()\n",
    "        self.module_list = nn.ModuleList(\n",
    "            [nn.Sequential(nn.Linear(in_channel, out_channel),\n",
    "                           nn.LayerNorm(out_channel),\n",
    "                           nn.ReLU(inplace=True),\n",
    "                           nn.Linear(out_channel, out_channel))\n",
    "             for in_channel in in_channels])\n",
    "        self.aggr_embed = nn.Sequential(\n",
    "            nn.LayerNorm(out_channel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(out_channel, out_channel),\n",
    "            nn.LayerNorm(out_channel))\n",
    "        self.apply(init_weights)\n",
    "\n",
    "    def forward(self,\n",
    "                continuous_inputs: List[torch.Tensor],\n",
    "                categorical_inputs: Optional[List[torch.Tensor]] = None) -> torch.Tensor:\n",
    "        for i in range(len(self.module_list)):\n",
    "            continuous_inputs[i] = self.module_list[i](continuous_inputs[i])\n",
    "        output = torch.stack(continuous_inputs).sum(dim=0)\n",
    "        if categorical_inputs is not None:\n",
    "            output += torch.stack(categorical_inputs).sum(dim=0)\n",
    "        return self.aggr_embed(output)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.typing import Adj\n",
    "from torch_geometric.typing import OptTensor\n",
    "from torch_geometric.typing import Size\n",
    "from torch_geometric.utils import softmax\n",
    "from torch_geometric.utils import subgraph\n",
    "\n",
    "from itertools import permutations\n",
    "\n",
    "class GlobalInteractorLayer(MessagePassing):\n",
    "\n",
    "    def __init__(self,\n",
    "                 embed_dim: int,\n",
    "                 num_heads: int = 8,\n",
    "                 dropout: float = 0.1,\n",
    "                 **kwargs) -> None:\n",
    "        super(GlobalInteractorLayer, self).__init__(aggr='add', node_dim=0, **kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.lin_q_node = nn.Linear(embed_dim, embed_dim)\n",
    "        self.lin_k_node = nn.Linear(embed_dim, embed_dim)\n",
    "        self.lin_k_edge = nn.Linear(embed_dim, embed_dim)\n",
    "        self.lin_v_node = nn.Linear(embed_dim, embed_dim)\n",
    "        self.lin_v_edge = nn.Linear(embed_dim, embed_dim)\n",
    "        self.lin_self = nn.Linear(embed_dim, embed_dim)\n",
    "        self.attn_drop = nn.Dropout(dropout)\n",
    "        self.lin_ih = nn.Linear(embed_dim, embed_dim)\n",
    "        self.lin_hh = nn.Linear(embed_dim, embed_dim)\n",
    "        self.out_proj = nn.Linear(embed_dim, embed_dim)\n",
    "        self.proj_drop = nn.Dropout(dropout)\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim * 4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(embed_dim * 4, embed_dim),\n",
    "            nn.Dropout(dropout))\n",
    "\n",
    "    def forward(self,\n",
    "                x: torch.Tensor,\n",
    "                edge_index: Adj,\n",
    "                edge_attr: torch.Tensor,\n",
    "                size: Size = None) -> torch.Tensor:\n",
    "        x = x + self._mha_block(self.norm1(x), edge_index, edge_attr, size)\n",
    "        x = x + self._ff_block(self.norm2(x))\n",
    "        return x\n",
    "\n",
    "    def message(self,\n",
    "                x_i: torch.Tensor,\n",
    "                x_j: torch.Tensor,\n",
    "                edge_attr: torch.Tensor,\n",
    "                index: torch.Tensor,\n",
    "                ptr: OptTensor,\n",
    "                size_i: Optional[int]) -> torch.Tensor:\n",
    "        query = self.lin_q_node(x_i).view(-1, self.num_heads, self.embed_dim // self.num_heads)\n",
    "        key_node = self.lin_k_node(x_j).view(-1, self.num_heads, self.embed_dim // self.num_heads)\n",
    "        key_edge = self.lin_k_edge(edge_attr).view(-1, self.num_heads, self.embed_dim // self.num_heads)\n",
    "        value_node = self.lin_v_node(x_j).view(-1, self.num_heads, self.embed_dim // self.num_heads)\n",
    "        value_edge = self.lin_v_edge(edge_attr).view(-1, self.num_heads, self.embed_dim // self.num_heads)\n",
    "        scale = (self.embed_dim // self.num_heads) ** 0.5\n",
    "        alpha = (query * (key_node + key_edge)).sum(dim=-1) / scale\n",
    "        alpha = softmax(alpha, index, ptr, size_i)\n",
    "        alpha = self.attn_drop(alpha)\n",
    "        return (value_node + value_edge) * alpha.unsqueeze(-1)\n",
    "\n",
    "    def update(self,\n",
    "               inputs: torch.Tensor,\n",
    "               x: torch.Tensor) -> torch.Tensor:\n",
    "        inputs = inputs.view(-1, self.embed_dim)\n",
    "        gate = torch.sigmoid(self.lin_ih(inputs) + self.lin_hh(x))\n",
    "        return inputs + gate * (self.lin_self(x) - inputs)\n",
    "\n",
    "    def _mha_block(self,\n",
    "                   x: torch.Tensor,\n",
    "                   edge_index: Adj,\n",
    "                   edge_attr: torch.Tensor,\n",
    "                   size: Size) -> torch.Tensor:\n",
    "        x = self.out_proj(self.propagate(edge_index=edge_index, x=x, edge_attr=edge_attr, size=size))\n",
    "        return self.proj_drop(x)\n",
    "\n",
    "    def _ff_block(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.mlp(x)\n",
    "\n",
    "class GlobalInteractor(nn.Module):\n",
    "    def __init__(self,\n",
    "                 historical_steps: int,\n",
    "                 embed_dim: int,\n",
    "                 edge_dim: int,\n",
    "                 num_modes: int = 1,\n",
    "                 num_heads: int = 8,\n",
    "                 num_layers: int = 3,\n",
    "                 dropout: float = 0.1) -> None:\n",
    "        super(GlobalInteractor, self).__init__()\n",
    "        self.historical_steps = historical_steps\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_modes = num_modes\n",
    "\n",
    "        self.rel_embed = MultipleInputEmbedding(in_channels=[edge_dim, edge_dim], out_channel=embed_dim)\n",
    "        self.global_interactor_layers = nn.ModuleList(\n",
    "            [GlobalInteractorLayer(embed_dim=embed_dim, num_heads=num_heads, dropout=dropout)\n",
    "             for _ in range(num_layers)])\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "        self.multihead_proj = nn.Linear(embed_dim, num_modes * embed_dim)\n",
    "        self.apply(init_weights)\n",
    "        \n",
    "    def forward(self,data,social_inp) -> torch.Tensor:\n",
    "        \n",
    "        social_out = torch.zeros([0,social_inp.shape[1],social_inp.shape[2]]).to(device)\n",
    "        for m in range(social_inp.shape[0]):\n",
    "            temp_inp = social_inp[m,:,:]\n",
    "            num_nodes = data['VALID_LEN'][m,0].item()\n",
    "            if num_nodes==1:\n",
    "                #social_out = torch.cat([social_out,torch.zeros([1,social_inp.shape[1],social_inp.shape[2]])],dim=0)\n",
    "                social_out = torch.cat([social_out,social_inp[[m],:,:]],dim=0)\n",
    "                continue\n",
    "            temp_edge_index = torch.LongTensor(list(permutations(range(num_nodes), 2))).t().contiguous().to(device)\n",
    "            temp_norm_center = data['NORM_CENTER'][m,:]\n",
    "            temp_heading = data['HEADINGS'][m]\n",
    "            \n",
    "            temp_rel_pos = temp_norm_center[temp_edge_index[0]] - temp_norm_center[temp_edge_index[1]]\n",
    "            temp_rel_theta = temp_heading[temp_edge_index[0]] - temp_heading[temp_edge_index[1]]\n",
    "            temp_rel_theta_cos = torch.cos(temp_rel_theta)\n",
    "            temp_rel_theta_sin = torch.sin(temp_rel_theta)\n",
    "            temp_rel_embed = self.rel_embed([temp_rel_pos, torch.cat((temp_rel_theta_cos, temp_rel_theta_sin), dim=-1)])\n",
    "            \n",
    "            x = temp_inp\n",
    "            for layer in self.global_interactor_layers:\n",
    "                x = layer(x,temp_edge_index,temp_rel_embed)\n",
    "            x = self.norm(x)  \n",
    "            x = self.multihead_proj(x).view(-1,self.num_modes,self.embed_dim)  \n",
    "            x = x.transpose(0,1)  \n",
    "            social_out = torch.cat([social_out,x],dim=0)\n",
    "        \n",
    "        return social_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-generic",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiPredictionHeader(nn.Module):\n",
    "    def __init__(self, d_model, out_size, dropout, reg_h_dim=128, dis_h_dim=128, cls_h_dim=128):\n",
    "        super(MultiPredictionHeader, self).__init__()\n",
    "        self.out_size = out_size\n",
    "        self.reg_mlp_veh = nn.Sequential(\n",
    "            nn.Linear(d_model, reg_h_dim * 2, bias=True),\n",
    "            nn.LayerNorm(reg_h_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(reg_h_dim * 2, reg_h_dim, bias=True),\n",
    "            nn.Linear(reg_h_dim, out_size, bias=True))\n",
    "        self.reg_mlp_bic = nn.Sequential(\n",
    "            nn.Linear(d_model, reg_h_dim * 2, bias=True),\n",
    "            nn.LayerNorm(reg_h_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(reg_h_dim * 2, reg_h_dim, bias=True),\n",
    "            nn.Linear(reg_h_dim, out_size, bias=True))\n",
    "        self.reg_mlp_ped = nn.Sequential(\n",
    "            nn.Linear(d_model, reg_h_dim * 2, bias=True),\n",
    "            nn.LayerNorm(reg_h_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(reg_h_dim * 2, reg_h_dim, bias=True),\n",
    "            nn.Linear(reg_h_dim, out_size, bias=True))\n",
    "        self.fusion3 = nn.Linear(4, 2, bias=True)\n",
    "        self.fusion4 = nn.Linear(4, 2, bias=True)\n",
    "        self.num_modes = 1\n",
    "        \n",
    "    def forward(self, feature_out,data,traj):\n",
    "        \n",
    "        pred = torch.zeros([*feature_out.shape[:2],self.out_size]).to(device)\n",
    "\n",
    "        pred[data['CLASS_LIST']==1] = self.reg_mlp_veh(feature_out[data['CLASS_LIST']==1])\n",
    "        pred[data['CLASS_LIST']==2] = self.reg_mlp_bic(feature_out[data['CLASS_LIST']==2])\n",
    "        pred[data['CLASS_LIST']==3] = self.reg_mlp_ped(feature_out[data['CLASS_LIST']==3])\n",
    "        \n",
    "        ori_pred = pred.view(*pred.shape[:-1], -1, 2)\n",
    "        pred = ori_pred.cumsum(dim=-2)\n",
    "        \n",
    "        fusion_phy = torch.zeros([pred.shape[0],pred.shape[1],1,12,2]).to(device)\n",
    "        fusion_phy = construct_target(fusion_phy,traj,self.num_modes)\n",
    "        \n",
    "        hist_outputs = fusion_phy.squeeze(2)\n",
    "        hist = hist_outputs.cumsum(axis=-2)\n",
    "        \n",
    "        final_cum = self.fusion3(torch.cat([pred, hist], -1))\n",
    "        final_ori = self.fusion4(torch.cat([ori_pred, hist_outputs], -1))\n",
    "        \n",
    "        return final_cum, final_ori\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-filename",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer_utils refer to Y. Liu, J. Zhang, L. Fang, Q. Jiang, and B. Zhou, \"Multimodal motion prediction with stacked transformers,\" In Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), virtually, pp. 7577-7586, Jun. 2021\n",
    "\n",
    "from Transformer_utils import (Decoder, DecoderLayer, Encoder, EncoderDecoder,\n",
    "                                 EncoderLayer, GeneratorWithParallelHeads626,\n",
    "                                 LinearEmbedding, MultiHeadAttention,\n",
    "                                 PointerwiseFeedforward, PositionalEncoding,\n",
    "                                 SublayerConnection)\n",
    "\n",
    "class MA_STTN_MAP(nn.Module):\n",
    "    def __init__(self, hist_inp_size, num_queries, dec_inp_size, dec_out_size, N, N_social,\n",
    "                d_model, d_ff, pos_dim, dist_dim, h, dropout):\n",
    "        super(MA_STTN_MAP, self).__init__()\n",
    "        self.num_queries = num_queries\n",
    "        c = copy.deepcopy\n",
    "        dropout_atten = dropout\n",
    "        attn = MultiHeadAttention(h, d_model, dropout=dropout_atten)\n",
    "        ff = PointerwiseFeedforward(d_model, d_ff, dropout)\n",
    "        position = PositionalEncoding(d_model, dropout)\n",
    "        \n",
    "        self.hist_tf = EncoderDecoder(\n",
    "            Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n",
    "            Decoder(DecoderLayer(d_model, c(attn), c(attn), c(ff), dropout), N),\n",
    "            nn.Sequential(LinearEmbedding(hist_inp_size, d_model), c(position)))\n",
    "        self.lane_enc = Encoder(EncoderLayer(\n",
    "            d_model, c(attn), c(ff), dropout), N_lane)\n",
    "        self.lane_dec = Decoder(DecoderLayer(\n",
    "            d_model, c(attn), c(attn), c(ff), dropout), N_lane)\n",
    "        self.lane_emb = LinearEmbedding(lane_inp_size, d_model)\n",
    "        self.phy_emb = nn.Sequential(\n",
    "            nn.Flatten(start_dim=-2,end_dim=-1),\n",
    "            nn.Linear(12*2, d_model, bias=True),\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model, d_model, bias=True))\n",
    "        self.pos_emb = nn.Sequential(\n",
    "            nn.Linear(2, pos_dim, bias=True),\n",
    "            nn.LayerNorm(pos_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(pos_dim, pos_dim, bias=True))\n",
    "        self.dist_emb = nn.Sequential(\n",
    "            nn.Linear(num_queries*d_model, dist_dim, bias=True),\n",
    "            nn.LayerNorm(dist_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dist_dim, dist_dim, bias=True))\n",
    "        \n",
    "        self.fusion1 = nn.Sequential(\n",
    "            nn.Linear(d_model+pos_dim, d_model, bias=True),\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model, d_model, bias=True))\n",
    "        self.fusion2 = nn.Sequential(\n",
    "            nn.Linear(dist_dim+pos_dim, d_model, bias=True),\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model, d_model, bias=True))\n",
    "        self.fusion3 = nn.Linear(4, 2, bias=True)\n",
    "        self.fusion4 = nn.Linear(4, 2, bias=True)\n",
    "        self.social_enc = Encoder(EncoderLayer(\n",
    "            d_model, c(attn), c(ff), dropout), N_social)\n",
    "        self.social_dec = Decoder(DecoderLayer(\n",
    "            d_model, c(attn), c(attn), c(ff), dropout), N_social)\n",
    "        \n",
    "        self.historical_steps = 8\n",
    "        self.edge_dim = 2\n",
    "        self.embed_dim = d_model\n",
    "        self.num_modes = num_queries\n",
    "        self.num_heads = 8\n",
    "        self.num_global_layers = 3\n",
    "        self.global_interactor = GlobalInteractor(historical_steps=self.historical_steps,\n",
    "                                    embed_dim=self.embed_dim,\n",
    "                                    edge_dim=self.edge_dim,\n",
    "                                    num_modes=self.num_modes,\n",
    "                                    num_heads=self.num_heads,\n",
    "                                    num_layers=self.num_global_layers,\n",
    "                                    dropout=dropout).to(device)\n",
    "        \n",
    "        \n",
    "        for name, param in self.named_parameters():\n",
    "            # print(name)\n",
    "            if param.dim() > 1:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "\n",
    "        self.query_embed = nn.Embedding(self.num_queries, d_model)\n",
    "        self.query_embed.weight.requires_grad == True\n",
    "        nn.init.orthogonal_(self.query_embed.weight)\n",
    "        \n",
    "        self.w1 = nn.Parameter(torch.FloatTensor(1), requires_grad=True).to(device)\n",
    "        self.w2 = nn.Parameter(torch.FloatTensor(1), requires_grad=True).to(device)\n",
    "        self.w3 = nn.Parameter(torch.FloatTensor(1), requires_grad=True).to(device)\n",
    "        \n",
    "        self.w1.data.fill_(1.0)\n",
    "        self.w2.data.fill_(1.0)\n",
    "        self.w3.data.fill_(1.0)\n",
    "        \n",
    "    def forward(self, traj, pos, max_agent_num, social_mask,lane_vec, lane_mask,data):\n",
    "        self.query_batches = self.query_embed.weight.view(\n",
    "            1, 1, *self.query_embed.weight.shape).repeat(*traj.shape[:2], 1, 1)\n",
    "        # Physics target construction\n",
    "        phy_tgt = torch.zeros([self.query_batches.shape[0],self.query_batches.shape[1],self.query_batches.shape[2],12,2]).to(device)\n",
    "        phy_tgt = construct_target(phy_tgt,traj,self.num_queries)\n",
    "        phy_tgt = self.phy_emb(phy_tgt)\n",
    "        \n",
    "        #historical information\n",
    "        hist_out = self.hist_tf(traj, phy_tgt, None, None, self.query_batches)\n",
    "        pos = self.pos_emb(pos)\n",
    "        hist_out = torch.cat([pos.unsqueeze(dim=2).repeat(\n",
    "                    1, 1, self.num_queries, 1), hist_out], dim=-1)\n",
    "        hist_out = self.fusion1(hist_out)\n",
    "        \n",
    "        #lane encoder\n",
    "        social_num = max_agent_num\n",
    "        lane_mem = self.lane_enc(self.lane_emb(lane_vec), lane_mask)\n",
    "        lane_mem = lane_mem.unsqueeze(1).repeat(1, social_num, 1, 1)\n",
    "        lane_mask = lane_mask.unsqueeze(1).repeat(1, social_num, 1, 1)\n",
    "        \n",
    "        # Lane decoder\n",
    "        lane_out = self.lane_dec(hist_out, lane_mem, lane_mask, None)\n",
    "        \n",
    "        # Fuse position information\n",
    "        dist = lane_out.view(*traj.shape[0:2], -1)\n",
    "        dist = self.dist_emb(dist)\n",
    "        \n",
    "        #Global Interactor\n",
    "        social_inp = self.fusion2(torch.cat([pos, dist], -1))\n",
    "        social_out = self.global_interactor(data,social_inp)\n",
    "        \n",
    "        feature_out = torch.cat([social_out,lane_out.squeeze(2),phy_tgt.squeeze(2)], -1)\n",
    "        \n",
    "        return feature_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-breed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameter\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device='cpu'\n",
    "\n",
    "#Multi-Agent Spatial-Temporal Transformer Network with MAP information\n",
    "hist_inp_size = 5\n",
    "#single-modal\n",
    "num_queries = 1\n",
    "lane_inp_size = 64\n",
    "dec_inp_size = 64\n",
    "dec_out_size = 24\n",
    "\n",
    "N = 2\n",
    "N_lane = 2\n",
    "N_social = 2\n",
    "d_model = 128\n",
    "d_ff = 256\n",
    "pos_dim = 64\n",
    "dist_dim = 128\n",
    "h = 4\n",
    "dropout = 0.1\n",
    "PredictionModel = MA_STTN_MAP(hist_inp_size, num_queries, dec_inp_size, dec_out_size, N, N_social, d_model, d_ff, pos_dim, dist_dim, h, dropout).to(device)\n",
    "\n",
    "#LaneNet for trajectory preprocessing\n",
    "lane_channels= 4\n",
    "subgraph_width = 32\n",
    "num_subgraph_layres =2\n",
    "lane_subgraph = LaneNet(lane_channels, subgraph_width, num_subgraph_layres).to(device)\n",
    "\n",
    "#Trajectory prediction header\n",
    "prediction_header = MultiPredictionHeader(d_model*3, dec_out_size, dropout).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radio-document",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_train_loss(traj_lab,outputs_coord,labels_mask):\n",
    "    muX = outputs_coord[:,:,:,[0]].to(device)\n",
    "    muY = outputs_coord[:,:,:,[1]].to(device)\n",
    "    x = traj_lab[:,:,:,[0]].to(device)\n",
    "    y = traj_lab[:,:,:,[1]].to(device)\n",
    "    each_err = torch.sqrt(torch.pow(x - muX, 2) + torch.pow(y - muY, 2))\n",
    "    sum_target_err = torch.sum(each_err,dim=2)\n",
    "    error_mask = torch.floor(torch.sum(labels_mask,dim=2)/12)\n",
    "    if torch.sum(error_mask)==0:\n",
    "        return torch.tensor([0.])\n",
    "    train_error = torch.sum(torch.mul(sum_target_err,error_mask))/(torch.sum(error_mask)*12)\n",
    "    return train_error\n",
    "\n",
    "def cal_metric(traj_lab,outputs_coord,labels_mask):\n",
    "    muX = outputs_coord[:,:,:,[0]].to(device)\n",
    "    muY = outputs_coord[:,:,:,[1]].to(device)\n",
    "    x = traj_lab[:,:,:,[0]].to(device)\n",
    "    y = traj_lab[:,:,:,[1]].to(device)\n",
    "    each_err = torch.sqrt(torch.pow(x - muX, 2) + torch.pow(y - muY, 2))\n",
    "    mean_target_err = torch.mean(each_err,dim=2)\n",
    "    final_target_err = each_err[:,:,-1,:]\n",
    "    error_mask = torch.floor(torch.sum(labels_mask,dim=2)/12)\n",
    "    if torch.sum(error_mask)==0:\n",
    "        return torch.tensor([0.]),torch.tensor([0.])\n",
    "    mean_error = torch.sum(torch.mul(mean_target_err,error_mask))/(torch.sum(error_mask))\n",
    "    final_error = torch.sum(torch.mul(final_target_err,error_mask))/(torch.sum(error_mask))\n",
    "    return mean_error,final_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-springer",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss=[]\n",
    "val_loss=[]\n",
    "validation_loss=[]\n",
    "\n",
    "from torch.nn import functional as f\n",
    "\n",
    "def train_model(PredictionModel,prediction_header,lane_subgraph,criterion,p_optimizer,num_epochs,log_interval=25,scheduler=None):\n",
    "    since = time.time()\n",
    "    best_prediction_model_wts = copy.deepcopy(PredictionModel.state_dict())\n",
    "    best_prediction_header_wts = copy.deepcopy(prediction_header.state_dict())\n",
    "    best_lane_subgraph_wts = copy.deepcopy(lane_subgraph.state_dict())\n",
    "    \n",
    "    best_loss = 100\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        iteration = 0\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                PredictionModel.train()  # Set model to training mode\n",
    "                prediction_header.train()\n",
    "                lane_subgraph.train()\n",
    "                #RewardModel.train()\n",
    "            else:\n",
    "                PredictionModel.eval()   # Set model to evaluate mode\n",
    "                prediction_header.eval()\n",
    "                lane_subgraph.eval()\n",
    "                #RewardModel.eval()\n",
    "                \n",
    "            running_loss = 0.0\n",
    "            show_model_error_mean = 0.0\n",
    "            show_model_error_final = 0.0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for batch_idx,data in enumerate(dataloaders[phase]):\n",
    "                B = data['HISTORY'].shape[0]\n",
    "                pos = data['NORM_CENTER']\n",
    "                traj = data['HISTORY']\n",
    "                lane = data['LANE_VECTORS']\n",
    "                traj_valid_len = data['VALID_LEN'][:,0]\n",
    "                max_agent_num = torch.max(traj_valid_len)\n",
    "                lane_valid_len = data['VALID_LEN'][:,1]\n",
    "                max_lane_num = torch.max(lane_valid_len)\n",
    "                \n",
    "                social_mask = preprocess_traj(data['HISTORY'],B,traj_valid_len,max_agent_num)\n",
    "                lane_vec, lane_mask = preprocess_lane(lane_subgraph,lane,B,lane_valid_len,max_lane_num)\n",
    "                \n",
    "                traj_lab = torch.zeros((0,data['FUTURE'].shape[1],12,2)).to(device)\n",
    "                labels = torch.zeros((0,data['FUTURE'].shape[1],12,2)).to(device)\n",
    "                for i in range(len(data['FUTURE'])):\n",
    "                    gt = data['FUTURE'][i,:,:,:2].unsqueeze(0)\n",
    "                    labels = torch.cat([labels,gt],dim=0)\n",
    "                    gt = gt.cumsum(axis=-2)\n",
    "                    traj_lab = torch.cat([traj_lab,gt],dim=0)\n",
    "                labels_mask = data['FUTURE'][:,:,:,[-1]]\n",
    "                \n",
    "                traj,pos,max_agent_num,social_mask,lane_vec,lane_mask,traj_lab,labels_mask = \\\n",
    "                        Variable(traj.to(device)),Variable(pos.to(device)),Variable(max_agent_num.to(device)),\\\n",
    "                        Variable(social_mask.to(device)),Variable(lane_vec.to(device)),Variable(lane_mask.to(device)),\\\n",
    "                        Variable(traj_lab.to(device)),Variable(labels_mask.to(device))\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    feature_out = PredictionModel(traj,pos,max_agent_num,social_mask,lane_vec,lane_mask,data)\n",
    "                    pred_cum,pred_ori = prediction_header(feature_out,data,traj)\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        p_optimizer.zero_grad()\n",
    "                        \n",
    "                        loss = cal_train_loss(traj_lab,pred_cum,labels_mask)\n",
    "                        loss.backward()\n",
    "                        \n",
    "                        p_optimizer.step()\n",
    "                        \n",
    "                    if phase == 'val':\n",
    "                        loss = cal_train_loss(traj_lab,pred_cum,labels_mask)\n",
    "                        vali_mean, vali_final = cal_metric(traj_lab,pred_cum,labels_mask)\n",
    "                # statistics\n",
    "                running_loss += loss.item() * B\n",
    "                \n",
    "                if phase == 'val':\n",
    "                    show_model_error_mean += vali_mean.item() * B\n",
    "                    show_model_error_final += vali_final.item() * B\n",
    "                if phase == 'train' and iteration % log_interval == 0:\n",
    "                    print('Train Epoch: {} [{}/{} ({:.0f}%)] Loss: {:.8f}'.format(\n",
    "                        epoch, batch_idx * B, dataset_sizes['train'],batch_idx * B/dataset_sizes['train']*100,loss.item()))\n",
    "                iteration += 1\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            \n",
    "            if phase == 'train':\n",
    "                train_loss.append(epoch_loss)\n",
    "                print('{} Loss: {:.8f}'.format(phase, epoch_loss, ))\n",
    "            else:\n",
    "                epoch_show_loss_mean = show_model_error_mean / dataset_sizes[phase]\n",
    "                epoch_show_loss_final = show_model_error_final / dataset_sizes[phase]\n",
    "                val_loss.append(epoch_loss)\n",
    "                print('{} Loss: {:.8f} Mean_Error: {:.8f} Final_Error {:.8f}'.format(phase, epoch_loss,epoch_show_loss_mean, epoch_show_loss_final))\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_loss < best_loss :\n",
    "                best_loss = epoch_loss\n",
    "                best_prediction_model_wts = copy.deepcopy(PredictionModel.state_dict())\n",
    "                best_prediction_header_wts = copy.deepcopy(prediction_header.state_dict())\n",
    "                best_lane_subgraph_wts = copy.deepcopy(lane_subgraph.state_dict())\n",
    "                torch.save(PredictionModel.state_dict(), r'PredictionModel_IntersectionA(%d).tar' %(epoch+1))\n",
    "                torch.save(prediction_header.state_dict(), r'prediction_header_IntersectionA(%d).tar' %(epoch+1))\n",
    "                torch.save(lane_subgraph.state_dict(), r'lane_subgraph_IntersectionA(%d).tar' %(epoch+1))\n",
    "                \n",
    "    if(scheduler):\n",
    "        scheduler.step()\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:8f}'.format(best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    torch.save(PredictionModel.state_dict(), r'PredictionModel_IntersectionA(Final).tar')\n",
    "    torch.save(prediction_header.state_dict(), r'prediction_header_IntersectionA(Final).tar')\n",
    "    torch.save(lane_subgraph.state_dict(), r'lane_subgraph_IntersectionA(Final).tar')\n",
    "    \n",
    "    PredictionModel.load_state_dict(best_prediction_model_wts)\n",
    "    prediction_header.load_state_dict(best_prediction_header_wts)\n",
    "    lane_subgraph.load_state_dict(best_lane_subgraph_wts)\n",
    "    torch.save(PredictionModel.state_dict(), r'PredictionModel_IntersectionA.tar')\n",
    "    torch.save(prediction_header.state_dict(), r'prediction_header_IntersectionA.tar')\n",
    "    torch.save(lane_subgraph.state_dict(), r'lane_subgraph_IntersectionA.tar')\n",
    "    \n",
    "    return PredictionModel,prediction_header,lane_subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-master",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import copy\n",
    "\n",
    "criterion = nn.MSELoss().to(device)\n",
    "p_optimizer = torch.optim.Adam([{'params': PredictionModel.parameters()},\n",
    "                                {'params': prediction_header.parameters()},\n",
    "                                {'params': lane_subgraph.parameters()}], lr=0.0001)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(p_optimizer, 15, gamma=0.1)\n",
    "\n",
    "PredictionModel,prediction_header,subgraph = train_model(PredictionModel,prediction_header,lane_subgraph,criterion,p_optimizer,num_epochs=200,log_interval=100,scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-cradle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-crime",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_data(data,lane_subgraph):\n",
    "    B = data['HISTORY'].shape[0]\n",
    "    pos = data['NORM_CENTER']\n",
    "    traj = data['HISTORY']\n",
    "    lane = data['LANE_VECTORS']\n",
    "    traj_valid_len = data['VALID_LEN'][:,0]\n",
    "    max_agent_num = torch.max(traj_valid_len)\n",
    "    lane_valid_len = data['VALID_LEN'][:,1]\n",
    "    max_lane_num = torch.max(lane_valid_len)\n",
    "    \n",
    "    social_mask = preprocess_traj(data['HISTORY'],B,traj_valid_len,max_agent_num)\n",
    "    lane_vec, lane_mask = preprocess_lane(lane_subgraph,lane,B,lane_valid_len,max_lane_num)\n",
    "    \n",
    "    traj_lab = torch.zeros((0,data['FUTURE'].shape[1],12,2)).to(device)\n",
    "    labels = torch.zeros((0,data['FUTURE'].shape[1],12,2)).to(device)\n",
    "    for i in range(len(data['FUTURE'])):\n",
    "        gt = data['FUTURE'][i,:,:,:2].unsqueeze(0)\n",
    "        labels = torch.cat([labels,gt],dim=0)\n",
    "        gt = gt.cumsum(axis=-2)\n",
    "        traj_lab = torch.cat([traj_lab,gt],dim=0)\n",
    "    labels_mask = data['FUTURE'][:,:,:,[-1]]\n",
    "    \n",
    "    traj,pos,max_agent_num,social_mask,lane_vec,lane_mask,traj_lab,labels_mask = \\\n",
    "            Variable(traj.to(device)),Variable(pos.to(device)),Variable(max_agent_num.to(device)),\\\n",
    "            Variable(social_mask.to(device)),Variable(lane_vec.to(device)),Variable(lane_mask.to(device)),\\\n",
    "            Variable(traj_lab.to(device)),Variable(labels_mask.to(device))\n",
    "    \n",
    "    return traj,pos,max_agent_num,social_mask,lane_vec,lane_mask,traj_lab,labels_mask\n",
    "\n",
    "def cal_test_metric(traj_lab,outputs_coord,labels_mask):\n",
    "    muX = outputs_coord[:,:,:,[0]].to(device)\n",
    "    muY = outputs_coord[:,:,:,[1]].to(device)\n",
    "    x = traj_lab[:,:,:,[0]].to(device)\n",
    "    y = traj_lab[:,:,:,[1]].to(device)\n",
    "    each_err = torch.sqrt(torch.pow(x - muX, 2) + torch.pow(y - muY, 2))\n",
    "    \n",
    "    error_mask = torch.floor(torch.sum(labels_mask,dim=2)/12)\n",
    "    err_mean = torch.zeros([4])\n",
    "    err_final = torch.zeros([4])\n",
    "    if torch.sum(error_mask)==0:\n",
    "        return err_mean,err_final\n",
    "    for i in range(4):\n",
    "        mean_target_err = torch.mean(each_err[:,:,:3*(i+1),:],dim=2)\n",
    "        final_target_err = each_err[:,:,3*(i+1)-1,:]\n",
    "        mean_error = torch.sum(torch.mul(mean_target_err,error_mask))/(torch.sum(error_mask))\n",
    "        final_error = torch.sum(torch.mul(final_target_err,error_mask))/(torch.sum(error_mask))\n",
    "        err_mean[i] = mean_error\n",
    "        err_final[i] = final_error\n",
    "    return err_mean,err_final\n",
    "\n",
    "def cal_RFDE(outputs,labels):\n",
    "    muX = outputs[:,:,[0]]\n",
    "    muY = outputs[:,:,[1]]\n",
    "    x = labels[:,:,[0]]\n",
    "    y = labels[:,:,[1]]\n",
    "    out =  torch.sqrt(torch.pow(x - muX, 2) + torch.pow(y - muY, 2))\n",
    "    lossSum = torch.sum(out[:,:,0],dim=0)\n",
    "    err_final_rela_son = torch.zeros([4])\n",
    "    err_final_rela_mom = torch.zeros([4])\n",
    "    for i in range(4):\n",
    "        err_final_rela_son[i] = lossSum[3*(i+1)-1]\n",
    "        err_final_rela_mom[i] = torch.sum(torch.sqrt(torch.pow(labels[:,3*(i+1)-1,[0]], 2) + torch.pow(labels[:,3*(i+1)-1,[1]], 2)))\n",
    "        \n",
    "    return err_final_rela_son,err_final_rela_mom\n",
    "\n",
    "# Set model to evaluate mode\n",
    "\n",
    "PredictionModel.eval()   \n",
    "prediction_header.eval()\n",
    "lane_subgraph.eval()\n",
    "\n",
    "errors_mean = torch.zeros([4])\n",
    "errors_final = torch.zeros([4])\n",
    "errors_final_son = torch.zeros([4])\n",
    "errors_final_mom = torch.zeros([4])\n",
    "\n",
    "for batch_idx,data in enumerate(dataloaders['test']):\n",
    "    \n",
    "    traj,pos,max_agent_num,social_mask,lane_vec,lane_mask,traj_lab,labels_mask = get_input_data(data,lane_subgraph)\n",
    "    B = traj.shape[0]\n",
    "    \n",
    "    feature_out = PredictionModel(traj,pos,max_agent_num,social_mask,lane_vec,lane_mask,data)\n",
    "    pred_cum,pred_ori = prediction_header(feature_out,data,traj)\n",
    "    err_mean, err_final = cal_test_metric(traj_lab,pred_cum,labels_mask)\n",
    "    \n",
    "    errors_mean += (err_mean*B).detach().numpy()\n",
    "    errors_final += (err_final*B).detach().numpy()\n",
    "    \n",
    "    error_mask = torch.floor(torch.sum(labels_mask,dim=2)/12)\n",
    "    remain_cum = pred_cum[error_mask[:,:,0]==1,:,:]\n",
    "    remain_traj_lab = traj_lab[error_mask[:,:,0]==1,:,:]\n",
    "    \n",
    "    err_final_rela_son,err_final_rela_mom = cal_RFDE(remain_cum,remain_traj_lab)\n",
    "    errors_final_son += (err_final_rela_son).detach().numpy()\n",
    "    errors_final_mom += (err_final_rela_mom).detach().numpy()\n",
    "    \n",
    "errors_mean = errors_mean / dataset_sizes['test']\n",
    "errors_final = errors_final / dataset_sizes['test']\n",
    "print('Target Mean Error(m) :',errors_mean)\n",
    "print('Target Final Error(m) :',errors_final)\n",
    "print('Target RFDE :',errors_final_son/errors_final_mom)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
